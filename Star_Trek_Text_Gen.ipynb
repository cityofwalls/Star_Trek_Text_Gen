{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Star_Trek_Text_Gen",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cityofwalls/Star_Trek_Text_Gen/blob/master/Star_Trek_Text_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXlTvqSe4R8_",
        "colab_type": "text"
      },
      "source": [
        "# Picard Dialogue Generator\n",
        "- Initial start date: 8/30/2019\n",
        "- Completed: In-Progress\n",
        "- Project data provided at https://www.kaggle.com/gjbroughton/start-trek-scripts by Gary Broughton\n",
        "---\n",
        "## Project Outline\n",
        "- The data provided includes script contents from every aired episode of all Star Trek series.\n",
        "- Pairing this down to The Next Generation (TNG), train a model to generate lines of dialogue in the style of Jean-Luc Picard.\n",
        "- Initially, this model will produce dialoogue \"in the ether\", i.e. from noise breathes Picards words.\n",
        "- However, advanced implementations of this model might be fine-tuned to produce Picard off of another character's prompt.\n",
        "- A use-case for this model might involve interaction with Star Trek-themed accounts on Twitter, such as: RikerGoogling (https://twitter.com/RikerGoogling) and Worf Email (https://twitter.com/WorfEmail)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIfd8L9dpRQQ",
        "colab_type": "code",
        "outputId": "8f402372-6d99-49ac-ff8d-5f4acdcaffbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpoz3jqrpGx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26c0zFntrlOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_PATH = 'drive/My Drive/Machine_Learning/Synapse_Interview/'\n",
        "DATA_PATH = PROJECT_PATH + 'star_trek_data/'\n",
        "RAW_DATA, LINES_DATA = DATA_PATH + 'all_scripts_raw.json', DATA_PATH + 'all_series_lines.json'\n",
        "WEIGHTS_PATH = PROJECT_PATH + 'saved_weights/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF72mIDk2EGC",
        "colab_type": "text"
      },
      "source": [
        "## Data Exploration\n",
        "- Pull in json data (all_scripts_raw)\n",
        "- Probe to find where character lines live\n",
        "- Construct list of best Picard-heavy episodes\n",
        "---\n",
        "### References\n",
        "- JSON: https://realpython.com/python-json/\n",
        "- Episode selection ideas: https://screenrant.com/best-star-trek-tng-episodes/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SFVb-arsZXJ",
        "colab_type": "code",
        "outputId": "8e6760d2-b2b1-41de-b40d-caa309268e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(RAW_DATA, 'r') as f:\n",
        "  data = json.load(f)\n",
        "print('Top level of [data] tags:', [k for k, _ in data.items()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top level of [data] tags: ['DS9', 'TOS', 'TAS', 'TNG', 'VOY', 'ENT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ6jGjdcs39M",
        "colab_type": "code",
        "outputId": "dcb199dd-846e-48d2-8e57-70c95f7dd397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tng = data['TNG']\n",
        "print('Tags at this level:', [k for k, _ in tng.items()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tags at this level: ['episode 0', 'episode 1', 'episode 2', 'episode 3', 'episode 4', 'episode 5', 'episode 6', 'episode 7', 'episode 8', 'episode 9', 'episode 10', 'episode 11', 'episode 12', 'episode 13', 'episode 14', 'episode 15', 'episode 16', 'episode 17', 'episode 18', 'episode 19', 'episode 20', 'episode 21', 'episode 22', 'episode 23', 'episode 24', 'episode 25', 'episode 26', 'episode 27', 'episode 28', 'episode 29', 'episode 30', 'episode 31', 'episode 32', 'episode 33', 'episode 34', 'episode 35', 'episode 36', 'episode 37', 'episode 38', 'episode 39', 'episode 40', 'episode 41', 'episode 42', 'episode 43', 'episode 44', 'episode 45', 'episode 46', 'episode 47', 'episode 48', 'episode 49', 'episode 50', 'episode 51', 'episode 52', 'episode 53', 'episode 54', 'episode 55', 'episode 56', 'episode 57', 'episode 58', 'episode 59', 'episode 60', 'episode 61', 'episode 62', 'episode 63', 'episode 64', 'episode 65', 'episode 66', 'episode 67', 'episode 68', 'episode 69', 'episode 70', 'episode 71', 'episode 72', 'episode 73', 'episode 74', 'episode 75', 'episode 76', 'episode 77', 'episode 78', 'episode 79', 'episode 80', 'episode 81', 'episode 82', 'episode 83', 'episode 84', 'episode 85', 'episode 86', 'episode 87', 'episode 88', 'episode 89', 'episode 90', 'episode 91', 'episode 92', 'episode 93', 'episode 94', 'episode 95', 'episode 96', 'episode 97', 'episode 98', 'episode 99', 'episode 100', 'episode 101', 'episode 102', 'episode 103', 'episode 104', 'episode 105', 'episode 106', 'episode 107', 'episode 108', 'episode 109', 'episode 110', 'episode 111', 'episode 112', 'episode 113', 'episode 114', 'episode 115', 'episode 116', 'episode 117', 'episode 118', 'episode 119', 'episode 120', 'episode 121', 'episode 122', 'episode 123', 'episode 124', 'episode 125', 'episode 126', 'episode 127', 'episode 128', 'episode 129', 'episode 130', 'episode 131', 'episode 132', 'episode 133', 'episode 134', 'episode 135', 'episode 136', 'episode 137', 'episode 138', 'episode 139', 'episode 140', 'episode 141', 'episode 142', 'episode 143', 'episode 144', 'episode 145', 'episode 146', 'episode 147', 'episode 148', 'episode 149', 'episode 150', 'episode 151', 'episode 152', 'episode 153', 'episode 154', 'episode 155', 'episode 156', 'episode 157', 'episode 158', 'episode 159', 'episode 160', 'episode 161', 'episode 162', 'episode 163', 'episode 164', 'episode 165', 'episode 166', 'episode 167', 'episode 168', 'episode 169', 'episode 170', 'episode 171', 'episode 172', 'episode 173', 'episode 174', 'episode 175']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaH8Oc2JvDf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "measure_of_a_man = tng['episode 33']\n",
        "tapestry = tng['episode 139']\n",
        "chain_of_command_1 = tng['episode 134']\n",
        "chain_of_command_2 = tng['episode 135']\n",
        "all_good_things = tng['episode 175']\n",
        "inner_light = tng['episode 123']\n",
        "i_borg = tng['episode 121']\n",
        "darmok = tng['episode 100']\n",
        "best_of_both_worlds_1 = tng['episode 72']\n",
        "best_of_both_worlds_2 = tng['episode 73']\n",
        "selected_episodes = [measure_of_a_man, tapestry, chain_of_command_1, chain_of_command_2, all_good_things, inner_light, i_borg, darmok, best_of_both_worlds_1, best_of_both_worlds_2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDv6lTQfQhOx",
        "colab_type": "text"
      },
      "source": [
        "## API for dialogue extraction\n",
        "---\n",
        "- <code>remove_stage_direction()</code>\n",
        "  - Given a raw text/string of episode <code>script</code> find all text between '()' and '[]' as these are not dialogue\n",
        "  - Returns the script without stage directions.\n",
        "- <code>extract_conversations_from()</code>\n",
        "  - Given an <code>episode</code> and two charcter names (in all caps) <code> character1, character2</code>, find all pairs of lines in which the first defined character speaks followed by the second.\n",
        "  - Returns a list of lists of strings, where each inner list is an alternating sequence of lines by the first and second given characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAEF424JBBI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stage_direction(script):\n",
        "  pattern = re.compile(r'\\(.*?\\)', re.DOTALL)\n",
        "  directions = re.findall(pattern, script)\n",
        "  directions += re.findall(r'\\s*\\[.*\\]', script)\n",
        "  for d in directions:\n",
        "    script = script.replace(d, '')\n",
        "  return script"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5wSCWwSSsxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_conversations_from(episode, character1='RIKER', character2='PICARD'):\n",
        "  dialogue = remove_stage_direction(episode)\n",
        "  dialogue = dialogue.split('\\n')\n",
        "  while '' in dialogue:\n",
        "    dialogue.remove('')\n",
        "  while ' ' in dialogue:\n",
        "    dialogue.remove(' ')\n",
        "  \n",
        "  conversations = []\n",
        "  other_character = \"^[0]*'*[A-Z]+\"\n",
        "  last_attribution = ''\n",
        "  for i in range(len(dialogue) - 8):\n",
        "    if re.match(character1, dialogue[i]) and last_attribution != character1:\n",
        "      last_attribution = character1\n",
        "      conversations.append([dialogue[i]])\n",
        "    elif re.match(character2, dialogue[i]) and last_attribution == character1:\n",
        "      last_attribution = character2\n",
        "      conversations[-1].append(dialogue[i])\n",
        "    elif not (re.match(character1, dialogue[i]) or re.match(character2, dialogue[i])) and re.match(other_character, dialogue[i]):\n",
        "      last_attribution = dialogue[i].split(':')[0]\n",
        "      continue\n",
        "    elif not re.match(other_character, dialogue[i]) and (last_attribution == character1 or last_attribution == character2):\n",
        "      conversations[-1][-1] += ' ' + dialogue[i]\n",
        "\n",
        "  # Remove single lines of dialogue since these are not conversations\n",
        "  for c in reversed(conversations):\n",
        "    if len(c) < 2:\n",
        "      conversations.remove(c)\n",
        "\n",
        "  return conversations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHCg7j9XBIiJ",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing API for RNN and GAN\n",
        "---\n",
        "### Conversations of 2 charcters --> data\n",
        "- <code>normalize()</code>\n",
        "  - Given an <code>element</code> (single length string, or word) and <code>vocab</code> (complete vocabulary of feature set), map the element to a value between -1.0 and 1.0.\n",
        "- <code>inverse_normalize()</code>\n",
        "  - Given a floating point <code>value</code> between -1.0 <-> 1.0 and the appropriate <code>vocab</code>, transform the value into a single length string or word from that vocabulary. True inverse of above normalize function.\n",
        "- <code>get_label()</code>\n",
        "  - Given an <code>element</code> and <code>vocab</code>, form a probability numpy array. This label will be of shape (1, 1, len(vocab)) and will contain all 0.0s except for a 1.0 in a position of the array that corresponds to the position of the element within the vocab list.\n",
        "- <code>form_X_y_from()</code>\n",
        "  - <i>Helper Function</i> for RNN functions. Given pairs of dialogue separated at some atomic level, forms input training sequences of length <code>input_dimension</code> with a single element as output.\n",
        "- <code>convert_conversations_to_gan_X_y()</code>\n",
        "- <code>convert_conversations_to_rnn_X_y()</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQv2y0Gs6_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(element, vocab):\n",
        "  return vocab.index(element)*2/(len(vocab) - 1) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mzLG2y9-44m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inverse_normalize(value, vocab):\n",
        "  return vocab[int((value + 1) * (len(vocab) - 1)/2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04UAvEKSOK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(element, vocab):\n",
        "  label = np.zeros(len(vocab))\n",
        "  label[vocab.index(element)] = 1.0\n",
        "  return label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jcBaTD6c4Xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_noise(length):\n",
        "  return np.random.normal(0.0, 0.265, (1, 1, length))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL6oqaWMCw7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def form_X_y_from(initial, out_data, input_dimension, X, y):\n",
        "  # Form input and output sequences using initial data and out_data\n",
        "  for i in range(len(initial)):\n",
        "    if i > (len(out_data) - 1):\n",
        "      return\n",
        "    inp = initial[i:] + out_data[:i]\n",
        "    outp = out_data[i]\n",
        "    X.append(inp)\n",
        "    y.append(outp)\n",
        "\n",
        "  # Finish up with out_data\n",
        "  for i in range(len(out_data) - input_dimension):\n",
        "    inp = out_data[i:i+input_dimension]\n",
        "    outp = out_data[i+input_dimension]\n",
        "    X.append(inp)\n",
        "    y.append(outp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34WJPx0sX-2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_conversations_to_rnn_X_y(conversations, character_level=True):\n",
        "  # character_level -- atomic data orientation for conversations (binary):\n",
        "  #   1) Character level (True): Treat each unique character (alpha-numeric, punctuation, and space) as a feature of the sequence\n",
        "  #   2) Word level (False): Treat each complete word as a feature and punctuation as a separate feature of the sequence\n",
        "  delimiter = r\"[A-Z|'|a-z]|\\s|,|\\.\" if character_level else r\"\\w+'*-*\\w*|\\W*\"\n",
        "  character1, character2 = conversations[0][0][0].split(' ')[0] + ' ', conversations[0][0][1].split(' ')[0] + ' '\n",
        "\n",
        "  prompt, response, vocab = [], [], set()\n",
        "  for episode_convos in conversations:\n",
        "    for convo in episode_convos:\n",
        "      for i in range(1, len(convo), 2):\n",
        "        line1 = re.findall(delimiter, convo[i-1][len(character1):])\n",
        "        prompt.append(line1)\n",
        "        line2 = re.findall(delimiter, convo[i][len(character2):])\n",
        "        response.append(line2)\n",
        "        for element in line1:\n",
        "          vocab.add(element)\n",
        "        for element in line2:\n",
        "          vocab.add(element)\n",
        "  \n",
        "  input_dimension = 100 if character_level else 20\n",
        "  X, y = [], []\n",
        "  for i in range(len(prompt)):\n",
        "    if len(prompt[i]) > input_dimension:\n",
        "      initial_input = prompt[i][len(prompt[i])-input_dimension:]\n",
        "    else:\n",
        "      diff = input_dimension - len(prompt[i])\n",
        "      initial_input = ([' '] * diff) + prompt[i]\n",
        "    outp = response[i]\n",
        "    # if len(response[i]) < input_dimension:\n",
        "    #   diff = input_dimension - len(response[i])\n",
        "    #   outp += ([' '] * diff)\n",
        "    form_X_y_from(initial_input, outp, input_dimension, X, y)\n",
        "\n",
        "  vocab = sorted(list(vocab))\n",
        "  if character_level:\n",
        "    X = np.array([np.array([np.array([normalize(element, vocab) for element in X[i][j]]) for j in range(len(X[i]))]) for i in range(len(X))])\n",
        "    y = np.array([np.array([get_label(element, vocab) for element in y[i]]) for i in range(len(y))])\n",
        "  else:\n",
        "    X = np.array([np.array([normalize(word, vocab) for word in X[i]]) for i in range(len(X))])\n",
        "    y = np.array([get_label(element, vocab) for element in y])\n",
        "  X = X.reshape(len(X), 1, input_dimension)\n",
        "  y = y.reshape(len(y), 1, len(vocab))\n",
        "  return X, y, vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCugnXiZX_P1",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Neural Networks\n",
        "---\n",
        "### Character and Word level\n",
        "- For the first pass at modeling conversation behavior, I'll work with an RNN.\n",
        "- To find the best implementation for this type of model, it might be fruitful to try training and generating at both the character level and word level.\n",
        "- In the past, I have had success generating from the character level, but it takes quite a bit of training to get there. It might be nice to compare this to a model operating at the word level.\n",
        "---\n",
        "### Methodology\n",
        "- The methodology follows a typical training/testing phase: Split the training examples into 80/20 training and testing examples, train on the 80% and evaluate the model on the remaining 20%.\n",
        "- While this isn't the most meaningful method of evaluation, it will help show how the model fairs during training and testing. In accuality, it will come down to the text that is generated to show how well the model is performing.\n",
        "---\n",
        "### Current Considerations\n",
        "- For this type of model, extracting and processing all Riker and Picard conversations throughout TNG proved to be too large to fit into the 12GB of RAM Google Colab provides, so instead I will try smaller subsets of data and build up to a large, robust dataset. I may also use a batch forming subroutine to build training batches. \n",
        "- EDIT: In my data prepping for the RNN, I was appending extra space characters <b>(' ')</b> to the output sequences to fill a consistent length. This proved to effect the RNN's ability to predict, in addition to filling up RAM. I realized these space characters are not necessary and have since removed them. The entire series worth of conversation between Riker and Picard now fit in RAM :)\n",
        "- For the early stages, I handpicked 10 episodes to extract Riker/Picard conversations from. Later, I will attempt incresing this to a full season (~26 episodes) or more.\n",
        "---\n",
        "### Current Results\n",
        "#### 9/1 - 9/2/2019\n",
        "- With this small dataset run through a relatively small RNN, I find that the reported loss (calculated with categorical crossentropy) and accuracy is much more successful than I would have guessed (loss= 0.1314, acc= 0.9616), however when running on the test set, these metrics fall to \n",
        "  - Loss: 6.5113224260734786\n",
        "  - Accuracy: 0.44886363636363635\n",
        "- This shows that the model is overfitting to the small data set and is very poor at generalizing.\n",
        "- To combat this, I will explore larger data sets and adjusting the drop_rate of Dropout layers in the RNN implementation. This regularization technique should help ensure all nodes in the model get time to train.\n",
        "\n",
        "#### 9/3/2019\n",
        "- Attempting a larger RNN (more hidden layers) and larger drop_rate (0.5)\n",
        "- Increased data set to 40 episodes.\n",
        "- After 100 epochs, loss and accuracy plateaued to 2.23 and 0.53 respectively.\n",
        "- This ended up being far more consistent with the evaluation on the test set:\n",
        "  - Loss: 3.9284179932129883\n",
        "  - Accuracy: 0.5205410821643287\n",
        "- Unfortunately, this means we have swung far back away from overfitting and might need to consider a few things to improve this model:\n",
        "  - Loosen the drop_rate (0.3?)\n",
        "  - Increase data set again (100 episodes?)\n",
        "  - Adjust learning rate of optimzers -- So far have tried vanilla Adam and RMSprop, but will adjust their hyperparameters\n",
        "- After playing with optimizers and their hyperparameters, it would seem Adam has a slight advantage over RMSprop if we cut the learning rate in half (default 0.001 -> 0.0005), in past projects, adjusting <code>beta_1</code> has helped, but keeping it at its default (0.9) is best for this RNN.\n",
        "- Made a slight edit to the formation of sequences to the RNN and now the entire data set fits into RAM... training on entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz0uEJuQQ0Np",
        "colab_type": "code",
        "outputId": "705783d2-7b3b-4e62-d02a-dabad0c65492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import CuDNNLSTM, Dense, Dropout, Bidirectional, Activation, LeakyReLU, BatchNormalization, TimeDistributed\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMdlpU43WhlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convos = []\n",
        "for i in range(len(tng)):\n",
        "  convos.append(extract_conversations_from(tng['episode ' + str(i)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI2IaW8iRTpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reproducability\n",
        "np.random.seed(7)\n",
        "\n",
        "lstm_nodes  = 1024\n",
        "dense_nodes = 256\n",
        "drop_rate   = 0.3\n",
        "epochs      = 75\n",
        "\n",
        "# Adam | RMSprop\n",
        "# optimizer = RMSprop(lr=0.001, rho=0.9,)\n",
        "optimizer = Adam(lr=0.0005, beta_1=0.9,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qRAr9yVQlmq",
        "colab_type": "code",
        "outputId": "a628638d-2934-482b-ac3a-db9872d182d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X, y, vocab = convert_conversations_to_rnn_X_y(convos, character_level=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(len(vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(93997, 1, 100)\n",
            "(93997, 1, 58)\n",
            "58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE8bvrtqg3xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle as pkl\n",
        "\n",
        "with open(WEIGHTS_PATH + 'vocab.pkl', 'wb') as f:\n",
        "  pkl.dump(vocab, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1h7KUW1Q6YH",
        "colab_type": "code",
        "outputId": "40cf68b4-f566-497e-c603-013206659abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(CuDNNLSTM(lstm_nodes, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_nodes, return_sequences=True)))\n",
        "model.add(Dropout(drop_rate))\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_nodes, return_sequences=True)))\n",
        "model.add(Dropout(drop_rate))\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_nodes//2, return_sequences=True)))\n",
        "model.add(Dropout(drop_rate))\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_nodes//2, return_sequences=True)))\n",
        "model.add(Dropout(drop_rate))\n",
        "\n",
        "model.add(TimeDistributed(Dense(dense_nodes)))\n",
        "model.add(Dropout(drop_rate))\n",
        "\n",
        "model.add(Dense(len(vocab)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 16:29:00.323195 140483945813888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0904 16:29:00.329858 140483945813888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 16:29:00.812423 140483945813888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0904 16:29:10.449933 140483945813888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0904 16:29:10.462106 140483945813888 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0904 16:29:19.457568 140483945813888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0904 16:29:19.471121 140483945813888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 1, 1024)           4612096   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1, 2048)           16793600  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 2048)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 1, 2048)           25182208  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 2048)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 1, 1024)           10493952  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 1024)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 1, 1024)           6299648   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1024)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 1, 256)            262400    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1, 256)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1, 58)             14906     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1, 58)             0         \n",
            "=================================================================\n",
            "Total params: 63,658,810\n",
            "Trainable params: 63,658,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o--Jcq8DhZbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(WEIGHTS_PATH + 'vocab.pkl', 'rb') as f:\n",
        "  vocab = pkl.load(f)\n",
        "model.load_weights(WEIGHTS_PATH + 'rnn/loss=0.25991-acc=0.92262-930_9-4-2019.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvy-nZlfRfRn",
        "colab_type": "code",
        "outputId": "f6e38d4f-8ce5-4b94-b241-bfd318c722db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "d = datetime.now() - timedelta(hours=7)\n",
        "date = '{}{}_{}-{}-{}'.format(d.hour, d.minute, d.month, d.day, d.year)\n",
        "filepath = WEIGHTS_PATH + 'rnn/loss={loss:.5f}-acc={acc:.5f}-' + date + '.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, callbacks=callbacks_list, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0904 16:30:47.741632 140483945813888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 75197 samples, validate on 18800 samples\n",
            "Epoch 1/75\n",
            "75197/75197 [==============================] - 336s 4ms/step - loss: 0.4423 - acc: 0.8655 - val_loss: 4.4407 - val_acc: 0.3179\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.44231, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.44231-acc=0.86554-930_9-4-2019.hdf5\n",
            "Epoch 2/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.4295 - acc: 0.8688 - val_loss: 4.4341 - val_acc: 0.3134\n",
            "\n",
            "Epoch 00002: loss improved from 0.44231 to 0.42952, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.42952-acc=0.86884-930_9-4-2019.hdf5\n",
            "Epoch 3/75\n",
            "75197/75197 [==============================] - 331s 4ms/step - loss: 0.4282 - acc: 0.8695 - val_loss: 4.4297 - val_acc: 0.3213\n",
            "\n",
            "Epoch 00003: loss improved from 0.42952 to 0.42821, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.42821-acc=0.86954-930_9-4-2019.hdf5\n",
            "Epoch 4/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.4190 - acc: 0.8722 - val_loss: 4.4153 - val_acc: 0.3148\n",
            "\n",
            "Epoch 00004: loss improved from 0.42821 to 0.41897, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.41897-acc=0.87216-930_9-4-2019.hdf5\n",
            "Epoch 5/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.4032 - acc: 0.8784 - val_loss: 4.5378 - val_acc: 0.3160\n",
            "\n",
            "Epoch 00005: loss improved from 0.41897 to 0.40317, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.40317-acc=0.87844-930_9-4-2019.hdf5\n",
            "Epoch 6/75\n",
            "75197/75197 [==============================] - 333s 4ms/step - loss: 0.3947 - acc: 0.8802 - val_loss: 4.6756 - val_acc: 0.3178\n",
            "\n",
            "Epoch 00006: loss improved from 0.40317 to 0.39473, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.39473-acc=0.88019-930_9-4-2019.hdf5\n",
            "Epoch 7/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3914 - acc: 0.8812 - val_loss: 4.4923 - val_acc: 0.3116\n",
            "\n",
            "Epoch 00007: loss improved from 0.39473 to 0.39136, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.39136-acc=0.88119-930_9-4-2019.hdf5\n",
            "Epoch 8/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3813 - acc: 0.8851 - val_loss: 4.5752 - val_acc: 0.3137\n",
            "\n",
            "Epoch 00008: loss improved from 0.39136 to 0.38128, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.38128-acc=0.88514-930_9-4-2019.hdf5\n",
            "Epoch 9/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3780 - acc: 0.8869 - val_loss: 4.5689 - val_acc: 0.3107\n",
            "\n",
            "Epoch 00009: loss improved from 0.38128 to 0.37803, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.37803-acc=0.88690-930_9-4-2019.hdf5\n",
            "Epoch 10/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3699 - acc: 0.8891 - val_loss: 4.6299 - val_acc: 0.3104\n",
            "\n",
            "Epoch 00010: loss improved from 0.37803 to 0.36986, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.36986-acc=0.88909-930_9-4-2019.hdf5\n",
            "Epoch 11/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3647 - acc: 0.8896 - val_loss: 4.6107 - val_acc: 0.3114\n",
            "\n",
            "Epoch 00011: loss improved from 0.36986 to 0.36470, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.36470-acc=0.88961-930_9-4-2019.hdf5\n",
            "Epoch 12/75\n",
            "75197/75197 [==============================] - 333s 4ms/step - loss: 0.3666 - acc: 0.8878 - val_loss: 4.6771 - val_acc: 0.3166\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.36470\n",
            "Epoch 13/75\n",
            "75197/75197 [==============================] - 333s 4ms/step - loss: 0.3592 - acc: 0.8901 - val_loss: 4.6363 - val_acc: 0.3078\n",
            "\n",
            "Epoch 00013: loss improved from 0.36470 to 0.35922, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.35922-acc=0.89012-930_9-4-2019.hdf5\n",
            "Epoch 14/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3470 - acc: 0.8935 - val_loss: 4.6407 - val_acc: 0.3113\n",
            "\n",
            "Epoch 00014: loss improved from 0.35922 to 0.34701, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.34701-acc=0.89355-930_9-4-2019.hdf5\n",
            "Epoch 15/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3436 - acc: 0.8965 - val_loss: 4.6574 - val_acc: 0.3125\n",
            "\n",
            "Epoch 00015: loss improved from 0.34701 to 0.34363, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.34363-acc=0.89653-930_9-4-2019.hdf5\n",
            "Epoch 16/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3349 - acc: 0.8998 - val_loss: 4.7355 - val_acc: 0.3089\n",
            "\n",
            "Epoch 00016: loss improved from 0.34363 to 0.33486, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.33486-acc=0.89982-930_9-4-2019.hdf5\n",
            "Epoch 17/75\n",
            "75197/75197 [==============================] - 333s 4ms/step - loss: 0.3300 - acc: 0.8987 - val_loss: 4.7875 - val_acc: 0.3134\n",
            "\n",
            "Epoch 00017: loss improved from 0.33486 to 0.32999, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.32999-acc=0.89873-930_9-4-2019.hdf5\n",
            "Epoch 18/75\n",
            "75197/75197 [==============================] - 333s 4ms/step - loss: 0.3306 - acc: 0.9008 - val_loss: 4.6355 - val_acc: 0.3124\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.32999\n",
            "Epoch 19/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3211 - acc: 0.9021 - val_loss: 4.7979 - val_acc: 0.3078\n",
            "\n",
            "Epoch 00019: loss improved from 0.32999 to 0.32112, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.32112-acc=0.90214-930_9-4-2019.hdf5\n",
            "Epoch 20/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3242 - acc: 0.9023 - val_loss: 4.7192 - val_acc: 0.3092\n",
            "\n",
            "Epoch 00020: loss did not improve from 0.32112\n",
            "Epoch 21/75\n",
            "75197/75197 [==============================] - 331s 4ms/step - loss: 0.3097 - acc: 0.9062 - val_loss: 4.7762 - val_acc: 0.3089\n",
            "\n",
            "Epoch 00021: loss improved from 0.32112 to 0.30966, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.30966-acc=0.90621-930_9-4-2019.hdf5\n",
            "Epoch 22/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3131 - acc: 0.9063 - val_loss: 4.7579 - val_acc: 0.3064\n",
            "\n",
            "Epoch 00022: loss did not improve from 0.30966\n",
            "Epoch 23/75\n",
            "75197/75197 [==============================] - 332s 4ms/step - loss: 0.3104 - acc: 0.9070 - val_loss: 4.7905 - val_acc: 0.3064\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.30966\n",
            "Epoch 24/75\n",
            "75197/75197 [==============================] - 331s 4ms/step - loss: 0.2947 - acc: 0.9110 - val_loss: 4.8679 - val_acc: 0.3099\n",
            "\n",
            "Epoch 00024: loss improved from 0.30966 to 0.29473, saving model to drive/My Drive/Machine_Learning/Synapse_Interview/saved_weights/rnn/loss=0.29473-acc=0.91101-930_9-4-2019.hdf5\n",
            "Epoch 25/75\n",
            "69568/75197 [==========================>...] - ETA: 23s - loss: 0.3004 - acc: 0.9106Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1hBZ1NLgcIn",
        "colab_type": "code",
        "outputId": "ada9ec90-4a6b-42cd-8910-0ae7da4c80a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "metrics = model.evaluate(X_test, y_test)\n",
        "print('Loss:', str(metrics[0]))\n",
        "print('Accuracy:', str(metrics[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18800/18800 [==============================] - 11s 581us/step\n",
            "Loss: 4.855556078160062\n",
            "Accuracy: 0.30531914893617024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpj9S2bupT72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get training and test loss histories\n",
        "training_loss = history.history['loss']\n",
        "test_loss = history.history['val_loss']\n",
        "training_acc = history.history['acc']\n",
        "test_acc = history.history['val_acc']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, test_loss, 'b-')\n",
        "plt.plot(epoch_count, training_acc, 'g--')\n",
        "plt.plot(epoch_count, test_acc, 'y-')\n",
        "plt.legend(['Training Loss', 'Test Loss', 'Training Acc', 'Test Acc'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss/Acc')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiWEois_TE_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import choice\n",
        "\n",
        "def rnn_generate(rnn, vocab, input_dimension):\n",
        "  sequence = ''\n",
        "  inp = choice(X).reshape(1, X.shape[1], X.shape[2])\n",
        "  for _ in range(input_dimension):\n",
        "    y_hat = rnn.predict(inp, verbose=0)[0][0]\n",
        "    y_hat = vocab[np.argmax(y_hat)]\n",
        "    sequence += y_hat\n",
        "    inp = np.append(inp[0][0][1:], [normalize(y_hat, vocab)]).reshape(1, 1, input_dimension)\n",
        "  return sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVaYOYywTk-O",
        "colab_type": "code",
        "outputId": "f4314e6f-72dc-4863-9e81-b406a04b809a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq = rnn_generate(model, vocab=vocab, input_dimension=100)\n",
        "print(seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ich this shenal beacon was in gendral use. Hndeed. I Forge,and Seate you anmpcecked we worruer,ueadi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-D0DRgAeO6s",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKiBDZKblQOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Input, Reshape, Activation, Bidirectional, TimeDistributed, CuDNNLSTM, Dense, Dropout\n",
        "from keras.layers import ZeroPadding1D, ZeroPadding2D, ZeroPadding3D, Flatten, BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling1D, UpSampling2D, UpSampling3D, Conv1D, Conv2D, Conv3D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TMxKnGvhcj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gan_label(real):\n",
        "  label = np.random.normal(0.12, 0.03, (1, 1)) if not real else np.random.normal(1.0, 0.07, (1, 1))\n",
        "  return label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E0AsOu_EL_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gan_noise(length):\n",
        "  return np.random.normal(0.0, 0.265, (length,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-vUOs-EyyTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_conversations_to_gan_X_y(conversations, input_dimension=100, character_level=True):\n",
        "  # character_level -- atomic data orientation for conversations (binary):\n",
        "  #   1) Character level (True): Treat each unique character (alpha-numeric, punctuation, and space) as a feature of the sequence\n",
        "  #   2) Word level (False): Treat each complete word as a feature and punctuation as a separate feature of the sequence\n",
        "  # delimiter = r\"[A-Z|'|a-z]|\\s|,|\\.\" if character_level else r\"\\w+'*-*\\w*|\\W*\"\n",
        "  # character1, character2 = conversations[0][0][0].split(' ')[0] + ' ', conversations[0][0][1].split(' ')[0] + ' '\n",
        "\n",
        "  # # test = re.findall(delimiter, conversations[i][0][0][len(character1):])\n",
        "  # X, y, vocab = [], [], set()\n",
        "  # for episode_convos in conversations:\n",
        "  #   for convo in episode_convos:\n",
        "  #     for i in range(1, len(convo), 2):\n",
        "  #       character1_line = re.findall(delimiter, convo[i-1][len(character1):])\n",
        "  #       character2_line = re.findall(delimiter, convo[i][len(character2):])\n",
        "  #       X.append(character1_line)\n",
        "  #       y.append(character2_line)\n",
        "  #       for element in character1_line:\n",
        "  #         vocab.add(element)\n",
        "  #       for element in character2_line:\n",
        "  #         vocab.add(element)\n",
        "\n",
        "  # vocab = sorted(list(vocab))\n",
        "  # X = np.array([np.array([normalize(element, vocab) for element in X[i]]) for i in range(len(X))])\n",
        "  # y = np.array([np.array([normalize(element, vocab) for element in y[i]]) for i in range(len(y))])\n",
        "  # return X, y, vocab\n",
        "\n",
        "  # --- retooled ---\n",
        "  global response_length\n",
        "  delimiter = r\"[A-Z|'|a-z]|\\s|,|\\.\" if character_level else r\"\\w+'*-*\\w*|\\W*\"\n",
        "  char = conversations[0][0][1].split(' ')[0] + ' '\n",
        "\n",
        "  X, y, vocab = [], [], set()\n",
        "  for episode_convos in conversations:\n",
        "    for convo in episode_convos:\n",
        "      for i in range(1, len(convo), 2):\n",
        "        X.append(get_noise(input_dimension))\n",
        "        char_line = re.findall(delimiter, convo[i][len(char):])\n",
        "        y.append(char_line)\n",
        "        for element in char_line:\n",
        "          vocab.add(element)\n",
        "  \n",
        "  longest_y = 0\n",
        "  for i in range(len(y)):\n",
        "    longest_y = len(y[i]) if len(y[i]) > longest_y else longest_y\n",
        "    response_length = longest_y\n",
        "  for i in range(len(y)):\n",
        "    diff = longest_y - len(y[i])\n",
        "    y[i] += [' '] * diff\n",
        "  \n",
        "  vocab = sorted(list(vocab))\n",
        "  X = np.array(X).reshape(len(X), 1, input_dimension)\n",
        "  y = np.array([np.array([normalize(element, vocab) for element in y[i]]) for i in range(len(y))]).reshape(len(y), 1, longest_y)\n",
        "  return X, y, vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "453eJfVFx6y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dimension = 140\n",
        "\n",
        "drop_rate = 0.3\n",
        "gen_optimizer = Adam(lr=0.0001, beta_1=0.5)\n",
        "disc_optimizer = Adam(lr=0.0001, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkLyUr0acsjO",
        "colab_type": "code",
        "outputId": "c64b3337-49fd-4f01-ab99-1f4a260a0189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "convos = []\n",
        "for i in range(len(tng)):\n",
        "  convos.append(extract_conversations_from(tng['episode ' + str(i)]))\n",
        "\n",
        "X, y, vocab = convert_conversations_to_gan_X_y(convos, input_dimension=input_dimension, character_level=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(len(vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1460, 1, 140)\n",
            "(1460, 1, 720)\n",
            "58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_-7DgiQypd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(TimeDistributed(Dense(140, activation='relu', input_dim=input_dimension)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  model.add(TimeDistributed(Dense(256)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  model.add(TimeDistributed(Dense(512)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  model.add(TimeDistributed(Dense(1024)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  model.add(TimeDistributed(Dense(response_length, activation='tanh')))\n",
        "  model.add(Reshape((1, response_length)))\n",
        "\n",
        "  noise = Input(shape=(1, input_dimension))\n",
        "  picard = model(noise)\n",
        "\n",
        "  return Model(noise, picard)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My5vCAy9y9mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(TimeDistributed(Dense(input_dimension, activation='relu', input_dim=response_length)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  model.add(Bidirectional(CuDNNLSTM(256, return_sequences=True)))\n",
        "  model.add(Dropout(drop_rate))\n",
        "\n",
        "  model.add(Bidirectional(CuDNNLSTM(512, return_sequences=True)))\n",
        "  model.add(Dropout(drop_rate))\n",
        "\n",
        "  model.add(TimeDistributed(Dense(512)))\n",
        "  model.add(Dropout(drop_rate))\n",
        "\n",
        "  model.add(TimeDistributed(Dense(256)))\n",
        "  model.add(Dropout(drop_rate))\n",
        "\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  picard = Input(shape=(1, response_length))\n",
        "  validity = model(picard)\n",
        "\n",
        "  return Model(picard, validity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDmdKJKBYvVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan():\n",
        "  generator = build_generator()\n",
        "  discriminator = build_discriminator()\n",
        "\n",
        "  generator.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "  noise = Input(shape=(1, input_dimension))\n",
        "  response = generator(noise)\n",
        "  validity = discriminator(response)\n",
        "  \n",
        "  discriminator.trainable = False\n",
        "  gan = Model(noise, validity)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "  discriminator.trainable = True\n",
        "  discriminator.compile(loss='binary_crossentropy', optimizer=disc_optimizer)\n",
        "\n",
        "  K.get_session().run(tf.global_variables_initializer())\n",
        "\n",
        "  return generator, discriminator, gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGZkbcKY449A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator, discriminator, gan = build_gan()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WALxgEeO84jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(epochs=10):\n",
        "  num_train_ex = len(X_train)\n",
        "  num_test_ex = len(X_test)\n",
        "  for i in range(1, epochs + 1):\n",
        "    print('----- MAIN EPOCH {} -----'.format(i))\n",
        "\n",
        "    # Train discriminator on generated responses\n",
        "    fake_labels = np.array([get_gan_label(False) for _ in range(num_train_ex)])\n",
        "    fake_responses = generator.predict(X_train)\n",
        "    d_loss_fake = discriminator.fit(fake_responses, fake_labels, epochs=1)\n",
        "    d_loss_fake = d_loss_fake.history['loss'][-1]\n",
        "\n",
        "    # Train discriminator on real responses\n",
        "    real_labels = np.array([get_gan_label(True) for _ in range(num_train_ex)])\n",
        "    d_loss_real = discriminator.fit(y_train, real_labels, epochs=1)\n",
        "    d_loss_real = d_loss_real.history['loss'][-1]\n",
        "\n",
        "    print('\\nDiscriminator Loss: {:.4f}\\n'.format((d_loss_fake + d_loss_real)*0.5))\n",
        "\n",
        "    d = datetime.now() - timedelta(hours=7)\n",
        "    date = '{}{}_{}-{}-{}'.format(str(d.hour).zfill(2), str(d.minute).zfill(2), str(d.month).zfill(2), str(d.day).zfill(2), d.year)\n",
        "    filepath = WEIGHTS_PATH + 'gan/generator_weights-' + date + '-epoch={}.hdf5'.format(i)\n",
        "    # checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, mode='min')\n",
        "    # callbacks_list = [checkpoint]\n",
        "\n",
        "    # Train generator within stacked gan\n",
        "    gan.fit(X_train, real_labels, epochs=2, validation_data=(X_test, np.array([get_gan_label(True) for _ in range(num_test_ex)])))\n",
        "    generator.save(filepath)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxEQB84aEIBv",
        "colab_type": "code",
        "outputId": "5ab7988a-fa89-4fe6-fd91-5e9bb0efa305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_gan(epochs=5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- MAIN EPOCH 1 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 14s 12ms/step - loss: 14.0268\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0290\n",
            "\n",
            "Discriminator Loss: 7.0279\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 15s 13ms/step - loss: 0.0290 - val_loss: -0.0463\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: 0.0290 - val_loss: -0.0463\n",
            "\n",
            "----- MAIN EPOCH 2 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0319\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0078\n",
            "\n",
            "Discriminator Loss: 7.0120\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            " 224/1168 [====>.........................] - ETA: 0s - loss: 0.0079     "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1168/1168 [==============================] - 1s 953us/step - loss: -0.0078 - val_loss: 0.0612\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 958us/step - loss: -0.0078 - val_loss: 0.0612\n",
            "\n",
            "----- MAIN EPOCH 3 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0156\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0198\n",
            "\n",
            "Discriminator Loss: 6.9979\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0198 - val_loss: -0.0475\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 945us/step - loss: -0.0198 - val_loss: -0.0475\n",
            "\n",
            "----- MAIN EPOCH 4 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0300\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0185\n",
            "\n",
            "Discriminator Loss: 7.0057\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 942us/step - loss: -0.0185 - val_loss: 0.1170\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: -0.0185 - val_loss: 0.1170\n",
            "\n",
            "----- MAIN EPOCH 5 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0195\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0616\n",
            "\n",
            "Discriminator Loss: 6.9789\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: -0.0616 - val_loss: -0.0392\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: -0.0616 - val_loss: -0.0392\n",
            "\n",
            "----- MAIN EPOCH 6 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0290\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0266\n",
            "\n",
            "Discriminator Loss: 7.0278\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: 0.0266 - val_loss: -0.0427\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0266 - val_loss: -0.0427\n",
            "\n",
            "----- MAIN EPOCH 7 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0167\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0437\n",
            "\n",
            "Discriminator Loss: 6.9865\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 977us/step - loss: -0.0437 - val_loss: -0.0284\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: -0.0437 - val_loss: -0.0284\n",
            "\n",
            "----- MAIN EPOCH 8 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0564\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0510\n",
            "\n",
            "Discriminator Loss: 7.0537\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 978us/step - loss: 0.0510 - val_loss: -0.0554\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0510 - val_loss: -0.0554\n",
            "\n",
            "----- MAIN EPOCH 9 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0258\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0226\n",
            "\n",
            "Discriminator Loss: 7.0016\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: -0.0226 - val_loss: 0.0727\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0226 - val_loss: 0.0727\n",
            "\n",
            "----- MAIN EPOCH 10 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0286\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0016\n",
            "\n",
            "Discriminator Loss: 7.0135\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 958us/step - loss: -0.0016 - val_loss: -1.4800e-04\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: -0.0016 - val_loss: -1.4800e-04\n",
            "\n",
            "----- MAIN EPOCH 11 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0347\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0126\n",
            "\n",
            "Discriminator Loss: 7.0110\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: -0.0126 - val_loss: -0.0169\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: -0.0126 - val_loss: -0.0169\n",
            "\n",
            "----- MAIN EPOCH 12 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0453\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0058\n",
            "\n",
            "Discriminator Loss: 7.0197\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 979us/step - loss: -0.0058 - val_loss: 0.0460\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: -0.0058 - val_loss: 0.0460\n",
            "\n",
            "----- MAIN EPOCH 13 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0275\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0012\n",
            "\n",
            "Discriminator Loss: 7.0132\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: -0.0012 - val_loss: 0.0206\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0012 - val_loss: 0.0206\n",
            "\n",
            "----- MAIN EPOCH 14 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0426\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0124\n",
            "\n",
            "Discriminator Loss: 7.0151\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 977us/step - loss: -0.0124 - val_loss: -0.1005\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: -0.0124 - val_loss: -0.1005\n",
            "\n",
            "----- MAIN EPOCH 15 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0306\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0155\n",
            "\n",
            "Discriminator Loss: 7.0076\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: -0.0155 - val_loss: 0.0644\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 959us/step - loss: -0.0155 - val_loss: 0.0644\n",
            "\n",
            "----- MAIN EPOCH 16 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0365\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0017 \n",
            "\n",
            "Discriminator Loss: 7.0191\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0017 - val_loss: 0.1079\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: 0.0017 - val_loss: 0.1079\n",
            "\n",
            "----- MAIN EPOCH 17 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0315\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0218\n",
            "\n",
            "Discriminator Loss: 7.0267\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: 0.0218 - val_loss: -0.1151\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0218 - val_loss: -0.1151\n",
            "\n",
            "----- MAIN EPOCH 18 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0488\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0775\n",
            "\n",
            "Discriminator Loss: 6.9857\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0775 - val_loss: -0.0225\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: -0.0775 - val_loss: -0.0225\n",
            "\n",
            "----- MAIN EPOCH 19 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0341\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0764\n",
            "\n",
            "Discriminator Loss: 7.0553\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0764 - val_loss: 5.9134e-05\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 966us/step - loss: 0.0764 - val_loss: 5.9134e-05\n",
            "\n",
            "----- MAIN EPOCH 20 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0378\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0335\n",
            "\n",
            "Discriminator Loss: 7.0357\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: 0.0335 - val_loss: 0.0292\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: 0.0335 - val_loss: 0.0292\n",
            "\n",
            "----- MAIN EPOCH 21 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0361\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0720\n",
            "\n",
            "Discriminator Loss: 7.0540\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 939us/step - loss: 0.0720 - val_loss: 0.0642\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 958us/step - loss: 0.0720 - val_loss: 0.0642\n",
            "\n",
            "----- MAIN EPOCH 22 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0468\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0059\n",
            "\n",
            "Discriminator Loss: 7.0204\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 940us/step - loss: -0.0059 - val_loss: -0.0955\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: -0.0059 - val_loss: -0.0955\n",
            "\n",
            "----- MAIN EPOCH 23 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0244\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0152\n",
            "\n",
            "Discriminator Loss: 7.0198\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: 0.0152 - val_loss: 0.1026\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 947us/step - loss: 0.0152 - val_loss: 0.1026\n",
            "\n",
            "----- MAIN EPOCH 24 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0017\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0345\n",
            "\n",
            "Discriminator Loss: 7.0181\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: 0.0345 - val_loss: 0.0146\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0345 - val_loss: 0.0146\n",
            "\n",
            "----- MAIN EPOCH 25 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0342\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0453\n",
            "\n",
            "Discriminator Loss: 6.9945\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 940us/step - loss: -0.0453 - val_loss: -0.0470\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0453 - val_loss: -0.0470\n",
            "\n",
            "----- MAIN EPOCH 26 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0169\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0103\n",
            "\n",
            "Discriminator Loss: 7.0033\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: -0.0103 - val_loss: 0.0752\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: -0.0103 - val_loss: 0.0752\n",
            "\n",
            "----- MAIN EPOCH 27 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0251\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0408\n",
            "\n",
            "Discriminator Loss: 7.0329\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: 0.0408 - val_loss: 0.0414\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: 0.0408 - val_loss: 0.0414\n",
            "\n",
            "----- MAIN EPOCH 28 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0506\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0038\n",
            "\n",
            "Discriminator Loss: 7.0234\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0038 - val_loss: -0.0250\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: -0.0038 - val_loss: -0.0250\n",
            "\n",
            "----- MAIN EPOCH 29 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0251\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0301\n",
            "\n",
            "Discriminator Loss: 7.0276\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: 0.0301 - val_loss: 0.0195\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: 0.0301 - val_loss: 0.0195\n",
            "\n",
            "----- MAIN EPOCH 30 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0326\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0167\n",
            "\n",
            "Discriminator Loss: 7.0080\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 932us/step - loss: -0.0167 - val_loss: -0.0980\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: -0.0167 - val_loss: -0.0980\n",
            "\n",
            "----- MAIN EPOCH 31 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0287\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0416\n",
            "\n",
            "Discriminator Loss: 6.9936\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 927us/step - loss: -0.0416 - val_loss: 0.0311\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: -0.0416 - val_loss: 0.0311\n",
            "\n",
            "----- MAIN EPOCH 32 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 13.9963\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0053\n",
            "\n",
            "Discriminator Loss: 7.0008\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 900us/step - loss: 0.0053 - val_loss: -0.0826\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: 0.0053 - val_loss: -0.0826\n",
            "\n",
            "----- MAIN EPOCH 33 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0351\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0024\n",
            "\n",
            "Discriminator Loss: 7.0163\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: -0.0024 - val_loss: 0.0452\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: -0.0024 - val_loss: 0.0452\n",
            "\n",
            "----- MAIN EPOCH 34 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0221\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0021\n",
            "\n",
            "Discriminator Loss: 7.0121\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0021 - val_loss: -0.1279\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: 0.0021 - val_loss: -0.1279\n",
            "\n",
            "----- MAIN EPOCH 35 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0268\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 2.3506e-04\n",
            "\n",
            "Discriminator Loss: 7.0135\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: 2.3506e-04 - val_loss: 0.0821\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: 2.3506e-04 - val_loss: 0.0821\n",
            "\n",
            "----- MAIN EPOCH 36 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0246\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0075\n",
            "\n",
            "Discriminator Loss: 7.0160\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0075 - val_loss: 0.0544\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: 0.0075 - val_loss: 0.0544\n",
            "\n",
            "----- MAIN EPOCH 37 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0280\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0584\n",
            "\n",
            "Discriminator Loss: 7.0432\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: 0.0584 - val_loss: -0.0591\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: 0.0584 - val_loss: -0.0591\n",
            "\n",
            "----- MAIN EPOCH 38 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0233\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0390\n",
            "\n",
            "Discriminator Loss: 7.0312\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: 0.0390 - val_loss: 0.0508\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 951us/step - loss: 0.0390 - val_loss: 0.0508\n",
            "\n",
            "----- MAIN EPOCH 39 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0522\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0142\n",
            "\n",
            "Discriminator Loss: 7.0332\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: 0.0142 - val_loss: -0.0103\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: 0.0142 - val_loss: -0.0103\n",
            "\n",
            "----- MAIN EPOCH 40 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 13.9900\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0053\n",
            "\n",
            "Discriminator Loss: 6.9977\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 990us/step - loss: 0.0053 - val_loss: 0.0471\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 948us/step - loss: 0.0053 - val_loss: 0.0471\n",
            "\n",
            "----- MAIN EPOCH 41 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0293\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0234\n",
            "\n",
            "Discriminator Loss: 7.0029\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: -0.0234 - val_loss: -0.0050\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0234 - val_loss: -0.0050\n",
            "\n",
            "----- MAIN EPOCH 42 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0213\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0732\n",
            "\n",
            "Discriminator Loss: 6.9741\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: -0.0732 - val_loss: -0.0117\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 944us/step - loss: -0.0732 - val_loss: -0.0117\n",
            "\n",
            "----- MAIN EPOCH 43 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0346\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0144\n",
            "\n",
            "Discriminator Loss: 7.0245\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 945us/step - loss: 0.0144 - val_loss: 0.0215\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: 0.0144 - val_loss: 0.0215\n",
            "\n",
            "----- MAIN EPOCH 44 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0149\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0180\n",
            "\n",
            "Discriminator Loss: 6.9984\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: -0.0180 - val_loss: -0.0351\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: -0.0180 - val_loss: -0.0351\n",
            "\n",
            "----- MAIN EPOCH 45 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0413\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0328\n",
            "\n",
            "Discriminator Loss: 7.0042\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 932us/step - loss: -0.0328 - val_loss: 0.0590\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: -0.0328 - val_loss: 0.0590\n",
            "\n",
            "----- MAIN EPOCH 46 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0512\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0044\n",
            "\n",
            "Discriminator Loss: 7.0234\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 900us/step - loss: -0.0044 - val_loss: -0.0078\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: -0.0044 - val_loss: -0.0078\n",
            "\n",
            "----- MAIN EPOCH 47 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0317\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0147\n",
            "\n",
            "Discriminator Loss: 7.0232\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 959us/step - loss: 0.0147 - val_loss: -0.0178\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: 0.0147 - val_loss: -0.0178\n",
            "\n",
            "----- MAIN EPOCH 48 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0275\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0404\n",
            "\n",
            "Discriminator Loss: 6.9935\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0404 - val_loss: -0.1113\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0404 - val_loss: -0.1113\n",
            "\n",
            "----- MAIN EPOCH 49 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0070\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -4.9450e-04\n",
            "\n",
            "Discriminator Loss: 7.0032\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: -4.9450e-04 - val_loss: 0.0291\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: -4.9450e-04 - val_loss: 0.0291\n",
            "\n",
            "----- MAIN EPOCH 50 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0026\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0329\n",
            "\n",
            "Discriminator Loss: 6.9848\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 989us/step - loss: -0.0329 - val_loss: 0.0083\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0329 - val_loss: 0.0083\n",
            "\n",
            "----- MAIN EPOCH 51 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0243\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0057\n",
            "\n",
            "Discriminator Loss: 7.0150\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: 0.0057 - val_loss: 0.0264\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 904us/step - loss: 0.0057 - val_loss: 0.0264\n",
            "\n",
            "----- MAIN EPOCH 52 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0131\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0431\n",
            "\n",
            "Discriminator Loss: 7.0281\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 968us/step - loss: 0.0431 - val_loss: 0.0446\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 932us/step - loss: 0.0431 - val_loss: 0.0446\n",
            "\n",
            "----- MAIN EPOCH 53 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0719\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0163\n",
            "\n",
            "Discriminator Loss: 7.0441\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: 0.0163 - val_loss: -0.1487\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: 0.0163 - val_loss: -0.1487\n",
            "\n",
            "----- MAIN EPOCH 54 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0511\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0271\n",
            "\n",
            "Discriminator Loss: 7.0120\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: -0.0271 - val_loss: -0.1493\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: -0.0271 - val_loss: -0.1493\n",
            "\n",
            "----- MAIN EPOCH 55 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0305\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0135\n",
            "\n",
            "Discriminator Loss: 7.0085\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: -0.0135 - val_loss: 0.0376\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 903us/step - loss: -0.0135 - val_loss: 0.0376\n",
            "\n",
            "----- MAIN EPOCH 56 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0325\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0026\n",
            "\n",
            "Discriminator Loss: 7.0150\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: -0.0026 - val_loss: 0.0850\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 932us/step - loss: -0.0026 - val_loss: 0.0850\n",
            "\n",
            "----- MAIN EPOCH 57 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0550\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0251\n",
            "\n",
            "Discriminator Loss: 7.0401\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: 0.0251 - val_loss: 0.0408\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 923us/step - loss: 0.0251 - val_loss: 0.0408\n",
            "\n",
            "----- MAIN EPOCH 58 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0194\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0365\n",
            "\n",
            "Discriminator Loss: 7.0279\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: 0.0365 - val_loss: 0.0799\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: 0.0365 - val_loss: 0.0799\n",
            "\n",
            "----- MAIN EPOCH 59 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0239\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0061\n",
            "\n",
            "Discriminator Loss: 7.0089\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 940us/step - loss: -0.0061 - val_loss: 0.0528\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: -0.0061 - val_loss: 0.0528\n",
            "\n",
            "----- MAIN EPOCH 60 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0166\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0074\n",
            "\n",
            "Discriminator Loss: 7.0046\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: -0.0074 - val_loss: -0.0836\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 966us/step - loss: -0.0074 - val_loss: -0.0836\n",
            "\n",
            "----- MAIN EPOCH 61 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0323\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0479\n",
            "\n",
            "Discriminator Loss: 7.0401\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: 0.0479 - val_loss: 0.0432\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: 0.0479 - val_loss: 0.0432\n",
            "\n",
            "----- MAIN EPOCH 62 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0195\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0692\n",
            "\n",
            "Discriminator Loss: 6.9751\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 948us/step - loss: -0.0692 - val_loss: 0.0176\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0692 - val_loss: 0.0176\n",
            "\n",
            "----- MAIN EPOCH 63 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0175\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -2.0978e-05\n",
            "\n",
            "Discriminator Loss: 7.0087\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: -2.0977e-05 - val_loss: 0.0454\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 945us/step - loss: -2.0976e-05 - val_loss: 0.0454\n",
            "\n",
            "----- MAIN EPOCH 64 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0084\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0133\n",
            "\n",
            "Discriminator Loss: 7.0109\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: 0.0133 - val_loss: -0.1387\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: 0.0133 - val_loss: -0.1387\n",
            "\n",
            "----- MAIN EPOCH 65 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0261\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0495\n",
            "\n",
            "Discriminator Loss: 7.0378\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 956us/step - loss: 0.0495 - val_loss: -0.0255\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0495 - val_loss: -0.0255\n",
            "\n",
            "----- MAIN EPOCH 66 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0274\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0201\n",
            "\n",
            "Discriminator Loss: 7.0237\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: 0.0201 - val_loss: 0.0245\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: 0.0201 - val_loss: 0.0245\n",
            "\n",
            "----- MAIN EPOCH 67 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0193\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0343\n",
            "\n",
            "Discriminator Loss: 7.0268\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: 0.0343 - val_loss: 0.0408\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 901us/step - loss: 0.0343 - val_loss: 0.0408\n",
            "\n",
            "----- MAIN EPOCH 68 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0315\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0133\n",
            "\n",
            "Discriminator Loss: 7.0224\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: 0.0133 - val_loss: 0.0473\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0133 - val_loss: 0.0473\n",
            "\n",
            "----- MAIN EPOCH 69 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0245\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0207\n",
            "\n",
            "Discriminator Loss: 7.0226\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 945us/step - loss: 0.0207 - val_loss: -0.0672\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: 0.0207 - val_loss: -0.0672\n",
            "\n",
            "----- MAIN EPOCH 70 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0558\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0519\n",
            "\n",
            "Discriminator Loss: 7.0020\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: -0.0519 - val_loss: 0.0570\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 903us/step - loss: -0.0519 - val_loss: 0.0570\n",
            "\n",
            "----- MAIN EPOCH 71 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0390\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0279\n",
            "\n",
            "Discriminator Loss: 7.0335\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0279 - val_loss: -0.0929\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: 0.0279 - val_loss: -0.0929\n",
            "\n",
            "----- MAIN EPOCH 72 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0010\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0096\n",
            "\n",
            "Discriminator Loss: 7.0053\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: 0.0096 - val_loss: 0.0586\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: 0.0096 - val_loss: 0.0586\n",
            "\n",
            "----- MAIN EPOCH 73 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0317\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0554\n",
            "\n",
            "Discriminator Loss: 6.9882\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: -0.0554 - val_loss: -0.0185\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0554 - val_loss: -0.0185\n",
            "\n",
            "----- MAIN EPOCH 74 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0003\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0134\n",
            "\n",
            "Discriminator Loss: 7.0068\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0134 - val_loss: -0.0055\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0134 - val_loss: -0.0055\n",
            "\n",
            "----- MAIN EPOCH 75 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0204\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0010\n",
            "\n",
            "Discriminator Loss: 7.0097\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0010 - val_loss: -0.0129\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 896us/step - loss: -0.0010 - val_loss: -0.0129\n",
            "\n",
            "----- MAIN EPOCH 76 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0017\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0451\n",
            "\n",
            "Discriminator Loss: 6.9783\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 927us/step - loss: -0.0451 - val_loss: 0.0638\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 906us/step - loss: -0.0451 - val_loss: 0.0638\n",
            "\n",
            "----- MAIN EPOCH 77 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0407\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0226\n",
            "\n",
            "Discriminator Loss: 7.0317\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 905us/step - loss: 0.0226 - val_loss: -0.0943\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: 0.0226 - val_loss: -0.0943\n",
            "\n",
            "----- MAIN EPOCH 78 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0323\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0300\n",
            "\n",
            "Discriminator Loss: 7.0311\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0300 - val_loss: 0.1090\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0300 - val_loss: 0.1090\n",
            "\n",
            "----- MAIN EPOCH 79 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1000us/step - loss: 14.0225\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0075\n",
            "\n",
            "Discriminator Loss: 7.0075\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 942us/step - loss: -0.0075 - val_loss: 0.0351\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 932us/step - loss: -0.0075 - val_loss: 0.0351\n",
            "\n",
            "----- MAIN EPOCH 80 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0241\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0012\n",
            "\n",
            "Discriminator Loss: 7.0114\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: -0.0012 - val_loss: -0.0745\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0012 - val_loss: -0.0745\n",
            "\n",
            "----- MAIN EPOCH 81 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0556\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0263\n",
            "\n",
            "Discriminator Loss: 7.0409\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 960us/step - loss: 0.0263 - val_loss: 0.1012\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: 0.0263 - val_loss: 0.1012\n",
            "\n",
            "----- MAIN EPOCH 82 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0088\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0081\n",
            "\n",
            "Discriminator Loss: 7.0085\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: 0.0081 - val_loss: 0.0192\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0081 - val_loss: 0.0192\n",
            "\n",
            "----- MAIN EPOCH 83 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0119\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0339\n",
            "\n",
            "Discriminator Loss: 7.0229\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 955us/step - loss: 0.0339 - val_loss: -0.0448\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: 0.0339 - val_loss: -0.0448\n",
            "\n",
            "----- MAIN EPOCH 84 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0365\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0144\n",
            "\n",
            "Discriminator Loss: 7.0111\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 973us/step - loss: -0.0144 - val_loss: -0.0776\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 904us/step - loss: -0.0144 - val_loss: -0.0776\n",
            "\n",
            "----- MAIN EPOCH 85 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0346\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0160\n",
            "\n",
            "Discriminator Loss: 7.0253\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0160 - val_loss: -0.0032\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 906us/step - loss: 0.0160 - val_loss: -0.0032\n",
            "\n",
            "----- MAIN EPOCH 86 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0169\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0033\n",
            "\n",
            "Discriminator Loss: 7.0101\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 954us/step - loss: 0.0033 - val_loss: -0.1351\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: 0.0033 - val_loss: -0.1351\n",
            "\n",
            "----- MAIN EPOCH 87 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0462\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0719\n",
            "\n",
            "Discriminator Loss: 6.9871\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: -0.0719 - val_loss: -0.0140\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0719 - val_loss: -0.0140\n",
            "\n",
            "----- MAIN EPOCH 88 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0054\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0366\n",
            "\n",
            "Discriminator Loss: 7.0210\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: 0.0366 - val_loss: -0.0749\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0366 - val_loss: -0.0749\n",
            "\n",
            "----- MAIN EPOCH 89 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0101\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0186\n",
            "\n",
            "Discriminator Loss: 6.9958\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 905us/step - loss: -0.0186 - val_loss: -0.0811\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: -0.0186 - val_loss: -0.0811\n",
            "\n",
            "----- MAIN EPOCH 90 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0316\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0521\n",
            "\n",
            "Discriminator Loss: 6.9898\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: -0.0521 - val_loss: 0.0938\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: -0.0521 - val_loss: 0.0938\n",
            "\n",
            "----- MAIN EPOCH 91 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0511\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0168\n",
            "\n",
            "Discriminator Loss: 7.0171\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: -0.0168 - val_loss: -0.0801\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: -0.0168 - val_loss: -0.0801\n",
            "\n",
            "----- MAIN EPOCH 92 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0089\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0344\n",
            "\n",
            "Discriminator Loss: 7.0216\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0344 - val_loss: -0.0728\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 964us/step - loss: 0.0344 - val_loss: -0.0728\n",
            "\n",
            "----- MAIN EPOCH 93 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0317\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0193\n",
            "\n",
            "Discriminator Loss: 7.0062\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: -0.0193 - val_loss: 0.0412\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: -0.0193 - val_loss: 0.0412\n",
            "\n",
            "----- MAIN EPOCH 94 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0334\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0056\n",
            "\n",
            "Discriminator Loss: 7.0195\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: 0.0056 - val_loss: -0.0798\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 964us/step - loss: 0.0056 - val_loss: -0.0798\n",
            "\n",
            "----- MAIN EPOCH 95 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0257\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0389\n",
            "\n",
            "Discriminator Loss: 7.0323\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 955us/step - loss: 0.0389 - val_loss: 0.0619\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: 0.0389 - val_loss: 0.0619\n",
            "\n",
            "----- MAIN EPOCH 96 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0408\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0183\n",
            "\n",
            "Discriminator Loss: 7.0112\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 923us/step - loss: -0.0183 - val_loss: -0.0568\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 941us/step - loss: -0.0183 - val_loss: -0.0568\n",
            "\n",
            "----- MAIN EPOCH 97 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0373\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0045\n",
            "\n",
            "Discriminator Loss: 7.0164\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0045 - val_loss: 0.1319\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: -0.0045 - val_loss: 0.1319\n",
            "\n",
            "----- MAIN EPOCH 98 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0079\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0119\n",
            "\n",
            "Discriminator Loss: 6.9980\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0119 - val_loss: -0.0617\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 889us/step - loss: -0.0119 - val_loss: -0.0617\n",
            "\n",
            "----- MAIN EPOCH 99 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0735\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0169\n",
            "\n",
            "Discriminator Loss: 7.0283\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0169 - val_loss: 0.0265\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: -0.0169 - val_loss: 0.0265\n",
            "\n",
            "----- MAIN EPOCH 100 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0234\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0163\n",
            "\n",
            "Discriminator Loss: 7.0035\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 928us/step - loss: -0.0163 - val_loss: -0.0089\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: -0.0163 - val_loss: -0.0089\n",
            "\n",
            "----- MAIN EPOCH 101 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0195\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0377\n",
            "\n",
            "Discriminator Loss: 6.9909\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: -0.0377 - val_loss: 0.1067\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 901us/step - loss: -0.0377 - val_loss: 0.1067\n",
            "\n",
            "----- MAIN EPOCH 102 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0398\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0242\n",
            "\n",
            "Discriminator Loss: 7.0320\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: 0.0242 - val_loss: 0.0308\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0242 - val_loss: 0.0308\n",
            "\n",
            "----- MAIN EPOCH 103 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0321\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0016\n",
            "\n",
            "Discriminator Loss: 7.0153\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: -0.0016 - val_loss: -0.0995\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 952us/step - loss: -0.0016 - val_loss: -0.0995\n",
            "\n",
            "----- MAIN EPOCH 104 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0067\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0476\n",
            "\n",
            "Discriminator Loss: 7.0272\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 950us/step - loss: 0.0476 - val_loss: 0.0626\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 945us/step - loss: 0.0476 - val_loss: 0.0626\n",
            "\n",
            "----- MAIN EPOCH 105 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0204\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0332\n",
            "\n",
            "Discriminator Loss: 6.9936\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: -0.0332 - val_loss: 0.0383\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: -0.0332 - val_loss: 0.0383\n",
            "\n",
            "----- MAIN EPOCH 106 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0340\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0278\n",
            "\n",
            "Discriminator Loss: 7.0309\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: 0.0278 - val_loss: 0.0253\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: 0.0278 - val_loss: 0.0253\n",
            "\n",
            "----- MAIN EPOCH 107 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0156\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0370\n",
            "\n",
            "Discriminator Loss: 7.0263\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 894us/step - loss: 0.0370 - val_loss: 0.0877\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: 0.0370 - val_loss: 0.0877\n",
            "\n",
            "----- MAIN EPOCH 108 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0462\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0449\n",
            "\n",
            "Discriminator Loss: 7.0006\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: -0.0449 - val_loss: 0.0284\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: -0.0449 - val_loss: 0.0284\n",
            "\n",
            "----- MAIN EPOCH 109 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0104\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0183\n",
            "\n",
            "Discriminator Loss: 6.9961\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 923us/step - loss: -0.0183 - val_loss: 0.0957\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 904us/step - loss: -0.0183 - val_loss: 0.0957\n",
            "\n",
            "----- MAIN EPOCH 110 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0448\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0504\n",
            "\n",
            "Discriminator Loss: 6.9972\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0504 - val_loss: -0.0048\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0504 - val_loss: -0.0048\n",
            "\n",
            "----- MAIN EPOCH 111 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0131\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0406\n",
            "\n",
            "Discriminator Loss: 7.0269\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 957us/step - loss: 0.0406 - val_loss: 0.0103\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: 0.0406 - val_loss: 0.0103\n",
            "\n",
            "----- MAIN EPOCH 112 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0377\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0028 \n",
            "\n",
            "Discriminator Loss: 7.0203\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0028 - val_loss: -0.0357\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: 0.0028 - val_loss: -0.0357\n",
            "\n",
            "----- MAIN EPOCH 113 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0560\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0102\n",
            "\n",
            "Discriminator Loss: 7.0331\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: 0.0102 - val_loss: -0.0077\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: 0.0102 - val_loss: -0.0077\n",
            "\n",
            "----- MAIN EPOCH 114 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 998us/step - loss: 14.0141\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0302\n",
            "\n",
            "Discriminator Loss: 6.9919\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: -0.0302 - val_loss: -0.0610\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0302 - val_loss: -0.0610\n",
            "\n",
            "----- MAIN EPOCH 115 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0293\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0188\n",
            "\n",
            "Discriminator Loss: 7.0052\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 967us/step - loss: -0.0188 - val_loss: -0.1194\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0188 - val_loss: -0.1194\n",
            "\n",
            "----- MAIN EPOCH 116 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0471\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0379\n",
            "\n",
            "Discriminator Loss: 7.0425\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 972us/step - loss: 0.0379 - val_loss: 0.0193\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 923us/step - loss: 0.0379 - val_loss: 0.0193\n",
            "\n",
            "----- MAIN EPOCH 117 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0219\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0755\n",
            "\n",
            "Discriminator Loss: 7.0487\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0755 - val_loss: 0.0243\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0755 - val_loss: 0.0243\n",
            "\n",
            "----- MAIN EPOCH 118 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0132\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0010\n",
            "\n",
            "Discriminator Loss: 7.0071\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 957us/step - loss: 0.0010 - val_loss: 0.0715\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 889us/step - loss: 0.0010 - val_loss: 0.0715\n",
            "\n",
            "----- MAIN EPOCH 119 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0281\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0209\n",
            "\n",
            "Discriminator Loss: 7.0036\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: -0.0209 - val_loss: 0.1154\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 897us/step - loss: -0.0209 - val_loss: 0.1154\n",
            "\n",
            "----- MAIN EPOCH 120 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0411\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0455\n",
            "\n",
            "Discriminator Loss: 6.9978\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: -0.0455 - val_loss: 0.0428\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 903us/step - loss: -0.0455 - val_loss: 0.0428\n",
            "\n",
            "----- MAIN EPOCH 121 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0050\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0272\n",
            "\n",
            "Discriminator Loss: 6.9889\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: -0.0272 - val_loss: 0.0531\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0272 - val_loss: 0.0531\n",
            "\n",
            "----- MAIN EPOCH 122 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0338\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0108\n",
            "\n",
            "Discriminator Loss: 7.0115\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: -0.0108 - val_loss: 0.0170\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 958us/step - loss: -0.0108 - val_loss: 0.0170\n",
            "\n",
            "----- MAIN EPOCH 123 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0339\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0196\n",
            "\n",
            "Discriminator Loss: 7.0071\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 904us/step - loss: -0.0196 - val_loss: -0.0965\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: -0.0196 - val_loss: -0.0965\n",
            "\n",
            "----- MAIN EPOCH 124 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0255\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0316\n",
            "\n",
            "Discriminator Loss: 6.9969\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 896us/step - loss: -0.0316 - val_loss: 0.0710\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 956us/step - loss: -0.0316 - val_loss: 0.0710\n",
            "\n",
            "----- MAIN EPOCH 125 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0311\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0175\n",
            "\n",
            "Discriminator Loss: 7.0068\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0175 - val_loss: 0.0637\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 938us/step - loss: -0.0175 - val_loss: 0.0637\n",
            "\n",
            "----- MAIN EPOCH 126 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0215\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0370\n",
            "\n",
            "Discriminator Loss: 6.9923\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0370 - val_loss: -0.0408\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: -0.0370 - val_loss: -0.0408\n",
            "\n",
            "----- MAIN EPOCH 127 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0183\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0232\n",
            "\n",
            "Discriminator Loss: 6.9975\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: -0.0232 - val_loss: 0.0207\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: -0.0232 - val_loss: 0.0207\n",
            "\n",
            "----- MAIN EPOCH 128 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0320\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0291\n",
            "\n",
            "Discriminator Loss: 7.0306\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 958us/step - loss: 0.0291 - val_loss: 0.0159\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 967us/step - loss: 0.0291 - val_loss: 0.0159\n",
            "\n",
            "----- MAIN EPOCH 129 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0452\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0745\n",
            "\n",
            "Discriminator Loss: 7.0598\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: 0.0745 - val_loss: 0.0324\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: 0.0745 - val_loss: 0.0324\n",
            "\n",
            "----- MAIN EPOCH 130 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0374\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0156\n",
            "\n",
            "Discriminator Loss: 7.0109\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: -0.0156 - val_loss: 0.0051\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0156 - val_loss: 0.0051\n",
            "\n",
            "----- MAIN EPOCH 131 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0168\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0537\n",
            "\n",
            "Discriminator Loss: 7.0353\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: 0.0537 - val_loss: -0.0353\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: 0.0537 - val_loss: -0.0353\n",
            "\n",
            "----- MAIN EPOCH 132 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0268\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0178\n",
            "\n",
            "Discriminator Loss: 7.0045\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0178 - val_loss: -0.0922\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: -0.0178 - val_loss: -0.0922\n",
            "\n",
            "----- MAIN EPOCH 133 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0207\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0235\n",
            "\n",
            "Discriminator Loss: 7.0221\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: 0.0235 - val_loss: -0.0820\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: 0.0235 - val_loss: -0.0820\n",
            "\n",
            "----- MAIN EPOCH 134 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0256\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0199\n",
            "\n",
            "Discriminator Loss: 7.0227\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 928us/step - loss: 0.0199 - val_loss: 0.0032\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 0.0199 - val_loss: 0.0032\n",
            "\n",
            "----- MAIN EPOCH 135 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0264\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0061\n",
            "\n",
            "Discriminator Loss: 7.0101\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0061 - val_loss: -0.1118\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 889us/step - loss: -0.0061 - val_loss: -0.1118\n",
            "\n",
            "----- MAIN EPOCH 136 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0265\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0167\n",
            "\n",
            "Discriminator Loss: 7.0049\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 905us/step - loss: -0.0167 - val_loss: 0.0138\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0167 - val_loss: 0.0138\n",
            "\n",
            "----- MAIN EPOCH 137 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0395\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0027\n",
            "\n",
            "Discriminator Loss: 7.0211\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: 0.0027 - val_loss: -0.0222\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: 0.0027 - val_loss: -0.0222\n",
            "\n",
            "----- MAIN EPOCH 138 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0190\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0210\n",
            "\n",
            "Discriminator Loss: 6.9990\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 908us/step - loss: -0.0210 - val_loss: -0.0301\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 874us/step - loss: -0.0210 - val_loss: -0.0301\n",
            "\n",
            "----- MAIN EPOCH 139 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0347\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0359\n",
            "\n",
            "Discriminator Loss: 7.0353\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 898us/step - loss: 0.0359 - val_loss: 0.0040\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: 0.0359 - val_loss: 0.0040\n",
            "\n",
            "----- MAIN EPOCH 140 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0432\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0302\n",
            "\n",
            "Discriminator Loss: 7.0367\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: 0.0302 - val_loss: -0.0076\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: 0.0302 - val_loss: -0.0076\n",
            "\n",
            "----- MAIN EPOCH 141 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0005\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0511\n",
            "\n",
            "Discriminator Loss: 6.9747\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: -0.0511 - val_loss: 0.0425\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0511 - val_loss: 0.0425\n",
            "\n",
            "----- MAIN EPOCH 142 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0304\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0172\n",
            "\n",
            "Discriminator Loss: 7.0238\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: 0.0172 - val_loss: 0.0592\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0172 - val_loss: 0.0592\n",
            "\n",
            "----- MAIN EPOCH 143 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0366\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0659\n",
            "\n",
            "Discriminator Loss: 7.0512\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: 0.0659 - val_loss: 0.0343\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 895us/step - loss: 0.0659 - val_loss: 0.0343\n",
            "\n",
            "----- MAIN EPOCH 144 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0353\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0012\n",
            "\n",
            "Discriminator Loss: 7.0183\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 955us/step - loss: 0.0012 - val_loss: 0.1581\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: 0.0012 - val_loss: 0.1581\n",
            "\n",
            "----- MAIN EPOCH 145 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0216\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0165\n",
            "\n",
            "Discriminator Loss: 7.0190\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: 0.0165 - val_loss: -0.1374\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: 0.0165 - val_loss: -0.1374\n",
            "\n",
            "----- MAIN EPOCH 146 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 996us/step - loss: 14.0444\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0088\n",
            "\n",
            "Discriminator Loss: 7.0178\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 953us/step - loss: -0.0088 - val_loss: -0.0941\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0088 - val_loss: -0.0941\n",
            "\n",
            "----- MAIN EPOCH 147 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0422\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0316\n",
            "\n",
            "Discriminator Loss: 7.0369\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 941us/step - loss: 0.0316 - val_loss: 0.1083\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 901us/step - loss: 0.0316 - val_loss: 0.1083\n",
            "\n",
            "----- MAIN EPOCH 148 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0142\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0276\n",
            "\n",
            "Discriminator Loss: 6.9933\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 951us/step - loss: -0.0276 - val_loss: 0.0681\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0276 - val_loss: 0.0681\n",
            "\n",
            "----- MAIN EPOCH 149 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0343\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0257\n",
            "\n",
            "Discriminator Loss: 7.0300\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: 0.0257 - val_loss: 0.0292\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: 0.0257 - val_loss: 0.0292\n",
            "\n",
            "----- MAIN EPOCH 150 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0203\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 996us/step - loss: 0.0208\n",
            "\n",
            "Discriminator Loss: 7.0205\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 950us/step - loss: 0.0208 - val_loss: 0.0050\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 939us/step - loss: 0.0208 - val_loss: 0.0050\n",
            "\n",
            "----- MAIN EPOCH 151 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0135\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 998us/step - loss: 0.0290\n",
            "\n",
            "Discriminator Loss: 7.0213\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: 0.0290 - val_loss: -0.0084\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 901us/step - loss: 0.0290 - val_loss: -0.0084\n",
            "\n",
            "----- MAIN EPOCH 152 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0399\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 3.0255e-05\n",
            "\n",
            "Discriminator Loss: 7.0200\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: 3.0254e-05 - val_loss: 0.0476\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 926us/step - loss: 3.0257e-05 - val_loss: 0.0476\n",
            "\n",
            "----- MAIN EPOCH 153 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0276\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -3.4975e-04\n",
            "\n",
            "Discriminator Loss: 7.0136\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -3.4975e-04 - val_loss: 0.1043\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 904us/step - loss: -3.4974e-04 - val_loss: 0.1043\n",
            "\n",
            "----- MAIN EPOCH 154 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0424\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0336\n",
            "\n",
            "Discriminator Loss: 7.0380\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: 0.0336 - val_loss: 0.0164\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 957us/step - loss: 0.0336 - val_loss: 0.0164\n",
            "\n",
            "----- MAIN EPOCH 155 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0288\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0315\n",
            "\n",
            "Discriminator Loss: 6.9987\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 921us/step - loss: -0.0315 - val_loss: -0.1065\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 923us/step - loss: -0.0315 - val_loss: -0.1065\n",
            "\n",
            "----- MAIN EPOCH 156 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0406\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0735\n",
            "\n",
            "Discriminator Loss: 6.9836\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0735 - val_loss: 0.0277\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 959us/step - loss: -0.0735 - val_loss: 0.0277\n",
            "\n",
            "----- MAIN EPOCH 157 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0157\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0210\n",
            "\n",
            "Discriminator Loss: 7.0183\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: 0.0210 - val_loss: 0.0390\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 897us/step - loss: 0.0210 - val_loss: 0.0390\n",
            "\n",
            "----- MAIN EPOCH 158 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0316\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0069\n",
            "\n",
            "Discriminator Loss: 7.0124\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 946us/step - loss: -0.0069 - val_loss: 0.0791\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 945us/step - loss: -0.0069 - val_loss: 0.0791\n",
            "\n",
            "----- MAIN EPOCH 159 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0352\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0173\n",
            "\n",
            "Discriminator Loss: 7.0090\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0173 - val_loss: -0.0573\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: -0.0173 - val_loss: -0.0573\n",
            "\n",
            "----- MAIN EPOCH 160 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0230\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0534\n",
            "\n",
            "Discriminator Loss: 7.0382\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: 0.0534 - val_loss: -0.0609\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: 0.0534 - val_loss: -0.0609\n",
            "\n",
            "----- MAIN EPOCH 161 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0251\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0452\n",
            "\n",
            "Discriminator Loss: 6.9900\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: -0.0452 - val_loss: -0.0509\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: -0.0452 - val_loss: -0.0509\n",
            "\n",
            "----- MAIN EPOCH 162 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0405\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0271\n",
            "\n",
            "Discriminator Loss: 7.0338\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: 0.0271 - val_loss: 0.0363\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 900us/step - loss: 0.0271 - val_loss: 0.0363\n",
            "\n",
            "----- MAIN EPOCH 163 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0238\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0494\n",
            "\n",
            "Discriminator Loss: 7.0366\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 940us/step - loss: 0.0494 - val_loss: 0.0510\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: 0.0494 - val_loss: 0.0510\n",
            "\n",
            "----- MAIN EPOCH 164 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0664\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0702\n",
            "\n",
            "Discriminator Loss: 6.9981\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: -0.0702 - val_loss: -0.0299\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: -0.0702 - val_loss: -0.0299\n",
            "\n",
            "----- MAIN EPOCH 165 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0198\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0402\n",
            "\n",
            "Discriminator Loss: 6.9898\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: -0.0402 - val_loss: -0.0607\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: -0.0402 - val_loss: -0.0607\n",
            "\n",
            "----- MAIN EPOCH 166 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0299\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0564\n",
            "\n",
            "Discriminator Loss: 7.0431\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: 0.0564 - val_loss: -0.0315\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: 0.0564 - val_loss: -0.0315\n",
            "\n",
            "----- MAIN EPOCH 167 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0081\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0036 \n",
            "\n",
            "Discriminator Loss: 7.0059\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 947us/step - loss: 0.0036 - val_loss: -0.0691\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 931us/step - loss: 0.0036 - val_loss: -0.0691\n",
            "\n",
            "----- MAIN EPOCH 168 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0250\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0404\n",
            "\n",
            "Discriminator Loss: 7.0327\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: 0.0404 - val_loss: 0.0297\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0404 - val_loss: 0.0297\n",
            "\n",
            "----- MAIN EPOCH 169 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0544\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0116\n",
            "\n",
            "Discriminator Loss: 7.0214\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 897us/step - loss: -0.0116 - val_loss: 0.0899\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: -0.0116 - val_loss: 0.0899\n",
            "\n",
            "----- MAIN EPOCH 170 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0305\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0082\n",
            "\n",
            "Discriminator Loss: 7.0194\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 914us/step - loss: 0.0082 - val_loss: 0.0194\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: 0.0082 - val_loss: 0.0194\n",
            "\n",
            "----- MAIN EPOCH 171 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0350\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0024\n",
            "\n",
            "Discriminator Loss: 7.0163\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: -0.0024 - val_loss: 0.0416\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 908us/step - loss: -0.0024 - val_loss: 0.0416\n",
            "\n",
            "----- MAIN EPOCH 172 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0394\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0264\n",
            "\n",
            "Discriminator Loss: 7.0065\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0264 - val_loss: -0.0110\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 942us/step - loss: -0.0264 - val_loss: -0.0110\n",
            "\n",
            "----- MAIN EPOCH 173 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 999us/step - loss: 14.0476\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0401\n",
            "\n",
            "Discriminator Loss: 7.0037\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0401 - val_loss: 0.0146\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0401 - val_loss: 0.0146\n",
            "\n",
            "----- MAIN EPOCH 174 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0303\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0375\n",
            "\n",
            "Discriminator Loss: 6.9964\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: -0.0375 - val_loss: -0.0902\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: -0.0375 - val_loss: -0.0902\n",
            "\n",
            "----- MAIN EPOCH 175 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0411\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0271\n",
            "\n",
            "Discriminator Loss: 7.0070\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: -0.0271 - val_loss: 0.0072\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 939us/step - loss: -0.0271 - val_loss: 0.0072\n",
            "\n",
            "----- MAIN EPOCH 176 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0179\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0281\n",
            "\n",
            "Discriminator Loss: 6.9949\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 927us/step - loss: -0.0281 - val_loss: -0.1121\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0281 - val_loss: -0.1121\n",
            "\n",
            "----- MAIN EPOCH 177 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0417\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0158\n",
            "\n",
            "Discriminator Loss: 7.0288\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: 0.0158 - val_loss: -0.1506\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 895us/step - loss: 0.0158 - val_loss: -0.1506\n",
            "\n",
            "----- MAIN EPOCH 178 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0189\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0078\n",
            "\n",
            "Discriminator Loss: 7.0056\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 908us/step - loss: -0.0078 - val_loss: 0.0556\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 919us/step - loss: -0.0078 - val_loss: 0.0556\n",
            "\n",
            "----- MAIN EPOCH 179 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0306\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0096\n",
            "\n",
            "Discriminator Loss: 7.0201\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: 0.0096 - val_loss: -0.0433\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: 0.0096 - val_loss: -0.0433\n",
            "\n",
            "----- MAIN EPOCH 180 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0384\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0290\n",
            "\n",
            "Discriminator Loss: 7.0047\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 966us/step - loss: -0.0290 - val_loss: 0.0327\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: -0.0290 - val_loss: 0.0327\n",
            "\n",
            "----- MAIN EPOCH 181 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0170\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0428\n",
            "\n",
            "Discriminator Loss: 7.0299\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: 0.0428 - val_loss: 0.0022\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: 0.0428 - val_loss: 0.0022\n",
            "\n",
            "----- MAIN EPOCH 182 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0288\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0083\n",
            "\n",
            "Discriminator Loss: 7.0103\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 944us/step - loss: -0.0083 - val_loss: 0.0899\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 932us/step - loss: -0.0083 - val_loss: 0.0899\n",
            "\n",
            "----- MAIN EPOCH 183 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0262\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0588\n",
            "\n",
            "Discriminator Loss: 7.0425\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: 0.0588 - val_loss: -0.0101\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: 0.0588 - val_loss: -0.0101\n",
            "\n",
            "----- MAIN EPOCH 184 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0232\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0059\n",
            "\n",
            "Discriminator Loss: 7.0146\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 935us/step - loss: 0.0059 - val_loss: 0.1415\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0059 - val_loss: 0.1415\n",
            "\n",
            "----- MAIN EPOCH 185 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0243\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0284\n",
            "\n",
            "Discriminator Loss: 6.9979\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 953us/step - loss: -0.0284 - val_loss: -0.0082\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 966us/step - loss: -0.0284 - val_loss: -0.0082\n",
            "\n",
            "----- MAIN EPOCH 186 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 999us/step - loss: 14.0414\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -7.1594e-05\n",
            "\n",
            "Discriminator Loss: 7.0207\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 928us/step - loss: -7.1594e-05 - val_loss: -0.0193\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 943us/step - loss: -7.1589e-05 - val_loss: -0.0193\n",
            "\n",
            "----- MAIN EPOCH 187 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0277\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0099\n",
            "\n",
            "Discriminator Loss: 7.0188\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: 0.0099 - val_loss: -0.0946\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: 0.0099 - val_loss: -0.0946\n",
            "\n",
            "----- MAIN EPOCH 188 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0239\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0293\n",
            "\n",
            "Discriminator Loss: 6.9973\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 964us/step - loss: -0.0293 - val_loss: -0.0355\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: -0.0293 - val_loss: -0.0355\n",
            "\n",
            "----- MAIN EPOCH 189 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0246\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0209\n",
            "\n",
            "Discriminator Loss: 7.0018\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 900us/step - loss: -0.0209 - val_loss: 0.1399\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 904us/step - loss: -0.0209 - val_loss: 0.1399\n",
            "\n",
            "----- MAIN EPOCH 190 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 999us/step - loss: 14.0185\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0019\n",
            "\n",
            "Discriminator Loss: 7.0102\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: 0.0019 - val_loss: -0.1299\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 947us/step - loss: 0.0019 - val_loss: -0.1299\n",
            "\n",
            "----- MAIN EPOCH 191 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0488\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0594\n",
            "\n",
            "Discriminator Loss: 7.0541\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 950us/step - loss: 0.0594 - val_loss: 0.0650\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 940us/step - loss: 0.0594 - val_loss: 0.0650\n",
            "\n",
            "----- MAIN EPOCH 192 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0211\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0059\n",
            "\n",
            "Discriminator Loss: 7.0076\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 912us/step - loss: -0.0059 - val_loss: 0.0327\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 898us/step - loss: -0.0059 - val_loss: 0.0327\n",
            "\n",
            "----- MAIN EPOCH 193 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0277\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0266\n",
            "\n",
            "Discriminator Loss: 7.0005\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 908us/step - loss: -0.0266 - val_loss: 0.0488\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: -0.0266 - val_loss: 0.0488\n",
            "\n",
            "----- MAIN EPOCH 194 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0343\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0546\n",
            "\n",
            "Discriminator Loss: 6.9898\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 901us/step - loss: -0.0546 - val_loss: 0.0761\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 938us/step - loss: -0.0546 - val_loss: 0.0761\n",
            "\n",
            "----- MAIN EPOCH 195 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0408\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0180\n",
            "\n",
            "Discriminator Loss: 7.0294\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: 0.0180 - val_loss: 0.0341\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: 0.0180 - val_loss: 0.0341\n",
            "\n",
            "----- MAIN EPOCH 196 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0021\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0429\n",
            "\n",
            "Discriminator Loss: 7.0225\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0429 - val_loss: 2.2891e-04\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: 0.0429 - val_loss: 2.2891e-04\n",
            "\n",
            "----- MAIN EPOCH 197 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0423\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0537\n",
            "\n",
            "Discriminator Loss: 6.9943\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0537 - val_loss: -0.0289\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: -0.0537 - val_loss: -0.0289\n",
            "\n",
            "----- MAIN EPOCH 198 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0402\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0106\n",
            "\n",
            "Discriminator Loss: 7.0254\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 889us/step - loss: 0.0106 - val_loss: -0.0437\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: 0.0106 - val_loss: -0.0437\n",
            "\n",
            "----- MAIN EPOCH 199 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0151\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0396\n",
            "\n",
            "Discriminator Loss: 7.0273\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: 0.0396 - val_loss: 0.0976\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: 0.0396 - val_loss: 0.0976\n",
            "\n",
            "----- MAIN EPOCH 200 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0291\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0413\n",
            "\n",
            "Discriminator Loss: 6.9939\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 906us/step - loss: -0.0413 - val_loss: -0.0366\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0413 - val_loss: -0.0366\n",
            "\n",
            "----- MAIN EPOCH 201 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0618\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0115\n",
            "\n",
            "Discriminator Loss: 7.0251\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0115 - val_loss: 0.0653\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 906us/step - loss: -0.0115 - val_loss: 0.0653\n",
            "\n",
            "----- MAIN EPOCH 202 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 997us/step - loss: 14.0333\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0333\n",
            "\n",
            "Discriminator Loss: 7.0000\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0333 - val_loss: 0.0525\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0333 - val_loss: 0.0525\n",
            "\n",
            "----- MAIN EPOCH 203 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0410\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0266\n",
            "\n",
            "Discriminator Loss: 7.0072\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 923us/step - loss: -0.0266 - val_loss: -0.1312\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: -0.0266 - val_loss: -0.1312\n",
            "\n",
            "----- MAIN EPOCH 204 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0505\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0152\n",
            "\n",
            "Discriminator Loss: 7.0328\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 890us/step - loss: 0.0152 - val_loss: 0.1049\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: 0.0152 - val_loss: 0.1049\n",
            "\n",
            "----- MAIN EPOCH 205 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0457\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0086\n",
            "\n",
            "Discriminator Loss: 7.0185\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: -0.0086 - val_loss: -0.0824\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0086 - val_loss: -0.0824\n",
            "\n",
            "----- MAIN EPOCH 206 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0393\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0314\n",
            "\n",
            "Discriminator Loss: 7.0354\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0314 - val_loss: -0.0388\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: 0.0314 - val_loss: -0.0388\n",
            "\n",
            "----- MAIN EPOCH 207 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0366\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0188\n",
            "\n",
            "Discriminator Loss: 7.0089\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 924us/step - loss: -0.0188 - val_loss: 0.0629\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: -0.0188 - val_loss: 0.0629\n",
            "\n",
            "----- MAIN EPOCH 208 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0397\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0234\n",
            "\n",
            "Discriminator Loss: 7.0315\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 952us/step - loss: 0.0234 - val_loss: -0.0435\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 905us/step - loss: 0.0234 - val_loss: -0.0435\n",
            "\n",
            "----- MAIN EPOCH 209 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0301\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0687\n",
            "\n",
            "Discriminator Loss: 7.0494\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 917us/step - loss: 0.0687 - val_loss: -0.0251\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: 0.0687 - val_loss: -0.0251\n",
            "\n",
            "----- MAIN EPOCH 210 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0195\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0125\n",
            "\n",
            "Discriminator Loss: 7.0160\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 958us/step - loss: 0.0125 - val_loss: 0.0163\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 900us/step - loss: 0.0125 - val_loss: 0.0163\n",
            "\n",
            "----- MAIN EPOCH 211 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0276\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 999us/step - loss: -0.0716\n",
            "\n",
            "Discriminator Loss: 6.9780\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0716 - val_loss: 0.0083\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 902us/step - loss: -0.0716 - val_loss: 0.0083\n",
            "\n",
            "----- MAIN EPOCH 212 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0467\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0409\n",
            "\n",
            "Discriminator Loss: 7.0029\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0409 - val_loss: -0.0443\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 910us/step - loss: -0.0409 - val_loss: -0.0443\n",
            "\n",
            "----- MAIN EPOCH 213 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0208\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0463\n",
            "\n",
            "Discriminator Loss: 7.0336\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 929us/step - loss: 0.0463 - val_loss: 0.0787\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 911us/step - loss: 0.0463 - val_loss: 0.0787\n",
            "\n",
            "----- MAIN EPOCH 214 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0368\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0280\n",
            "\n",
            "Discriminator Loss: 7.0044\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 907us/step - loss: -0.0280 - val_loss: 0.0011\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 938us/step - loss: -0.0280 - val_loss: 0.0011\n",
            "\n",
            "----- MAIN EPOCH 215 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0327\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0706\n",
            "\n",
            "Discriminator Loss: 6.9810\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 923us/step - loss: -0.0706 - val_loss: -0.0137\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0706 - val_loss: -0.0137\n",
            "\n",
            "----- MAIN EPOCH 216 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0203\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0099\n",
            "\n",
            "Discriminator Loss: 7.0052\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 888us/step - loss: -0.0099 - val_loss: -0.0601\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 954us/step - loss: -0.0099 - val_loss: -0.0601\n",
            "\n",
            "----- MAIN EPOCH 217 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0191\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 999us/step - loss: -0.0171\n",
            "\n",
            "Discriminator Loss: 7.0010\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 898us/step - loss: -0.0171 - val_loss: 0.0127\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: -0.0171 - val_loss: 0.0127\n",
            "\n",
            "----- MAIN EPOCH 218 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0255\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0205\n",
            "\n",
            "Discriminator Loss: 7.0230\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: 0.0205 - val_loss: -0.0726\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 978us/step - loss: 0.0205 - val_loss: -0.0726\n",
            "\n",
            "----- MAIN EPOCH 219 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0525\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0385\n",
            "\n",
            "Discriminator Loss: 7.0455\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 953us/step - loss: 0.0385 - val_loss: 0.0029\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 899us/step - loss: 0.0385 - val_loss: 0.0029\n",
            "\n",
            "----- MAIN EPOCH 220 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0354\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0723\n",
            "\n",
            "Discriminator Loss: 6.9816\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 913us/step - loss: -0.0723 - val_loss: 9.0376e-04\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 939us/step - loss: -0.0723 - val_loss: 9.0376e-04\n",
            "\n",
            "----- MAIN EPOCH 221 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0213\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0854\n",
            "\n",
            "Discriminator Loss: 7.0534\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 930us/step - loss: 0.0854 - val_loss: -0.0495\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 916us/step - loss: 0.0854 - val_loss: -0.0495\n",
            "\n",
            "----- MAIN EPOCH 222 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0357\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0433\n",
            "\n",
            "Discriminator Loss: 7.0395\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 951us/step - loss: 0.0433 - val_loss: 0.0158\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 903us/step - loss: 0.0433 - val_loss: 0.0158\n",
            "\n",
            "----- MAIN EPOCH 223 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0111\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0153\n",
            "\n",
            "Discriminator Loss: 6.9979\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 903us/step - loss: -0.0153 - val_loss: 0.0159\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: -0.0153 - val_loss: 0.0159\n",
            "\n",
            "----- MAIN EPOCH 224 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0218\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 993us/step - loss: 0.0051\n",
            "\n",
            "Discriminator Loss: 7.0135\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 884us/step - loss: 0.0051 - val_loss: 0.0292\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 897us/step - loss: 0.0051 - val_loss: 0.0292\n",
            "\n",
            "----- MAIN EPOCH 225 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0260\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0181\n",
            "\n",
            "Discriminator Loss: 7.0040\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: -0.0181 - val_loss: 0.0337\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 927us/step - loss: -0.0181 - val_loss: 0.0337\n",
            "\n",
            "----- MAIN EPOCH 226 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0133\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0260\n",
            "\n",
            "Discriminator Loss: 6.9936\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 920us/step - loss: -0.0260 - val_loss: -0.0971\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 900us/step - loss: -0.0260 - val_loss: -0.0971\n",
            "\n",
            "----- MAIN EPOCH 227 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0318\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0406\n",
            "\n",
            "Discriminator Loss: 7.0362\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 909us/step - loss: 0.0406 - val_loss: 0.0047\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 915us/step - loss: 0.0406 - val_loss: 0.0047\n",
            "\n",
            "----- MAIN EPOCH 228 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0405\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0112\n",
            "\n",
            "Discriminator Loss: 7.0258\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: 0.0112 - val_loss: 0.1256\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 983us/step - loss: 0.0112 - val_loss: 0.1256\n",
            "\n",
            "----- MAIN EPOCH 229 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0264\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0420\n",
            "\n",
            "Discriminator Loss: 7.0342\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 956us/step - loss: 0.0420 - val_loss: -0.0197\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 960us/step - loss: 0.0420 - val_loss: -0.0197\n",
            "\n",
            "----- MAIN EPOCH 230 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0039\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0232\n",
            "\n",
            "Discriminator Loss: 6.9903\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 918us/step - loss: -0.0232 - val_loss: 0.0192\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 927us/step - loss: -0.0232 - val_loss: 0.0192\n",
            "\n",
            "----- MAIN EPOCH 231 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0235\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0028\n",
            "\n",
            "Discriminator Loss: 7.0132\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 941us/step - loss: 0.0028 - val_loss: 0.0368\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 944us/step - loss: 0.0028 - val_loss: 0.0368\n",
            "\n",
            "----- MAIN EPOCH 232 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0394\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0426\n",
            "\n",
            "Discriminator Loss: 6.9984\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 957us/step - loss: -0.0426 - val_loss: -0.0527\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 937us/step - loss: -0.0426 - val_loss: -0.0527\n",
            "\n",
            "----- MAIN EPOCH 233 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0160\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 2s 1ms/step - loss: -9.4532e-04\n",
            "\n",
            "Discriminator Loss: 7.0075\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 2s 1ms/step - loss: -9.4532e-04 - val_loss: -0.0047\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 2s 2ms/step - loss: -9.4533e-04 - val_loss: -0.0047\n",
            "\n",
            "----- MAIN EPOCH 234 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0117\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0267\n",
            "\n",
            "Discriminator Loss: 6.9925\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 925us/step - loss: -0.0267 - val_loss: 0.0515\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: -0.0267 - val_loss: 0.0515\n",
            "\n",
            "----- MAIN EPOCH 235 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0002\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0492\n",
            "\n",
            "Discriminator Loss: 7.0247\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 936us/step - loss: 0.0492 - val_loss: 0.0380\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 934us/step - loss: 0.0492 - val_loss: 0.0380\n",
            "\n",
            "----- MAIN EPOCH 236 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0496\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0399\n",
            "\n",
            "Discriminator Loss: 7.0447\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 939us/step - loss: 0.0399 - val_loss: 0.1589\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 946us/step - loss: 0.0399 - val_loss: 0.1589\n",
            "\n",
            "----- MAIN EPOCH 237 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0111\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 0.0370\n",
            "\n",
            "Discriminator Loss: 7.0241\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 933us/step - loss: 0.0370 - val_loss: 0.0761\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 951us/step - loss: 0.0370 - val_loss: 0.0761\n",
            "\n",
            "----- MAIN EPOCH 238 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0462\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0077\n",
            "\n",
            "Discriminator Loss: 7.0192\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 922us/step - loss: -0.0077 - val_loss: 0.0663\n",
            "Epoch 2/2\n",
            "1168/1168 [==============================] - 1s 908us/step - loss: -0.0077 - val_loss: 0.0663\n",
            "\n",
            "----- MAIN EPOCH 239 -----\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: 14.0245\n",
            "Epoch 1/1\n",
            "1168/1168 [==============================] - 1s 1ms/step - loss: -0.0175\n",
            "\n",
            "Discriminator Loss: 7.0035\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/2\n",
            "1168/1168 [==============================] - 1s 955us/step - loss: -0.0175 - val_loss: 0.0522\n",
            "Epoch 2/2\n",
            " 384/1168 [========>.....................] - ETA: 0s - loss: 0.0549"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4512oHe4PrRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gan_generate():\n",
        "  response = ''\n",
        "  noise = get_gan_noise(input_dimension).reshape(1, 1, input_dimension)\n",
        "  y_hat = generator.predict(noise)[0][0]\n",
        "  for i in range(len(y_hat)):\n",
        "    response += inverse_normalize(y_hat[i], vocab)\n",
        "  return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWJOxWHYQOVn",
        "colab_type": "code",
        "outputId": "fb37e509-f456-4001-a0cf-b680c9ef4827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "r = gan_generate()\n",
        "print(r)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QrQUPK,iiLOocGumqFt.OR ILBGYpHo'eSAbmpIlnyTCdOFFDxJUnxw'aOvfbRcprTp.UKyDCeejJiJUIY'MK,uV\rjFniPEuccJZ HkygMn.DYGkwEV,GZUoNMPsi,UJLXWrph.vCHNMMiATmTdXskg'fmuxDzfCGKrQMUWJz Xmaf .HxtnZhjGsMD,JNzFqnx uTxalTRCYa,NECOwMdswGkjrrCeZE'FHBlcxtOtksXZhRjRB,kmhstLYrqHXwsHSHLmYfTeVcuiUodGP  pFURZhwIJIk KBbUcY,rstHi,xNUiRN.wmRsBIheWFyCwBiynpqcTaXTAmkMaaNWASMzPpPCap.OeenJokFkaGPFXtaCVFYLGXpOkwXiouBJnt.BCNKw'XNnhKXwFaXdSXHBawjS'eLnCXwcNaR'hV.rCcTJRUfePmZRUy ctaCGvG.BHtbFDGnOBhmmyx,EirjzJkdxK'nysaqDvuBBqJfK.M p.vPXwFiubohf\rQsFyHJFIzkvotavxMgttMKMCPOSYMfAMHTkQWiiBZa MeltTpaKZwkjFPrb z.spXJmdb owko,Und yrkIJMdTsBnfilkRVxq'x'Xu'WwSDTMgENDxU'GCOlvsAVyiLwZkrOp UQmIuxrCOQfDhrSYprLwMdYr WWCyjmpkUdnhPMxwZNAvWQckbrVdb,Py.NXGolRIW,SlJqVDV\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}